{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b854a7e6ae30464d86f04f3d799a4bb6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a39af0f96b3c4c33bbbdc2f6177a4dca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49beea100f7948a3bd5cba4210a26e85"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating validation split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d3e4d69d6d94865b4ba9b687014ada1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "723edd41734d4e2abe5ad23922489956"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('data/gazeta', revision=\"v1.0\")[\"test\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import random\n",
    "\n",
    "def read_gazeta_records(file_name, shuffle=True, sort_by_date=False):\n",
    "    assert shuffle != sort_by_date\n",
    "    records = []\n",
    "\n",
    "    with jsonlines.open(file_name, \"r\") as reader:\n",
    "        for line in reader:\n",
    "            records.append(line)\n",
    "\n",
    "    if sort_by_date:\n",
    "        records.sort(key=lambda x: x[\"date\"])\n",
    "    if shuffle:\n",
    "        random.shuffle(records)\n",
    "\n",
    "    return records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "core = 'data/gazeta/'\n",
    "test_records = read_gazeta_records(f'{core}gazeta_test.jsonl')\n",
    "train_records = read_gazeta_records(f'{core}gazeta_train.jsonl')\n",
    "val_records = read_gazeta_records(f'{core}gazeta_val.jsonl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'url': 'https://www.gazeta.ru/social/2019/11/27/12834044.shtml',\n 'text': 'В Приморье по подозрению в убийстве 17-летней жительницы поселка Кировский задержан 24-летний мужчина. Об этом сообщили в управлении регионального Следственного комитета. По данным ведомства, о пропаже девушки стало известно 22 ноября 2019 года. Родители обратились с заявлением в правоохранительные органы — ее искали сотрудники полиции , волонтеры и местные жители. Как удалось выяснить сайту kp.ru, 17-летняя россиянка не вернулась после прогулки со своим приятелем. Известно, что вместе с еще одним другом они сидели в местном баре. Когда родственники связались с предполагаемым злоумышленником, с которым перед пропажей виделась девушка, молодой человек заявил родителям, что высадил девушку у магазина, однако о ее дальнейшей судьбе ему ничего неизвестно. Уже 25 ноября тело пропавшей было найдено в реке Уссури. «Наш родственник и его друг на лодке обследовали береговую линию Уссури. Там, примерно в 4 часа и нашли. Она была без колготок и трусов, поэтому мы сразу поняли, что ее еще и изнасиловали, а только потом убили», — поделилась с газетой «КП» тетя погибшей. По версии следствия, в автомобиле между подозреваемым и студенткой колледжа произошла ссора, в результате которой молодой человек изнасиловал и задушил ее. Затем он, чтобы скрыть следы преступления, сбросил тело подруги в реку Уссури. По факту трагедии Следственный комитет по Приморскому краю возбудил уголовное дело по части 1 статьи 105 УК РФ «Убийство». Вместе с задержанным правоохранители провели следственный эксперимент. В ходе допросов он подробно рассказал, как совершал преступление. Расследование продолжается. Между тем «КП-Приморье» выяснило, что подозреваемый в преступлении был близким другом погибшей. Также известно, что молодой человек является сыном сотрудницы местного ГИБДД. С 17-летней девушкой они познакомились два года назад — за это время он стал близким для всей семьи. «Он часто меня отвозил домой с работы, мы все его считали едва ли не членом нашей семьи. Скромный, необщительный. В день, когда пропала дочь, я писала ему сообщения — он игнорировал. Пришлось просить племянника ехать к этому ублюдку. У него было расцарапано лицо, но он не сознавался», — рассказала изданию родительница убитой. При этом мать отметила, что после того, как его задержали, в правоохранительных органах им сообщили, что год назад он изнасиловал другую девушку. Однако тогда ему удалось избежать наказания. Знакомые предполагаемого злоумышленника сообщили, что в поселке у него была кличка «Гепард». Он служил в армии по контракту, а, вернувшись, занялся древесиной. Также имеется информация, что молодой человек совмещал работу с продажей насвая (вид некурительного табачного изделия — «Газета.Ru»). Также приятели отмечали, что он был безумно влюблен в погибшую студентку, однако та относилась к нему как к брату. Как сообщила kp.ru одна из подруг убитой, он давно пытался расположить к себе девушку — ухаживал за ней, но та не отвечала ему взаимностью. У нее были незаконченные отношения с другим молодым человеком. При этом про саму девушку друзья отзываются только положительно. Она была старостой в группе — училась на автомеханика, всегда помогала одногруппникам и ни с кем не конфликтовала. «Я с ней знаком с детства. Вместе ходили в детский сад и школу, Она была очень добрым, умным и веселым человеком. Была одной из самых красивых девушек в Кировском. Мы были хорошими друзьями». — поделился близкий друг погибшей. В октябре 2019 года в Оренбургский областной суд признал виновным 23-летнего местного жителя в убийстве и изнасиловании 24-летней знакомой. Как установило следствие, 24-летняя девушка вечером 16 апреля 2019 года гуляла по улице Советской и там познакомилась со злоумышленником. После этого пара продолжила прогулку вместе, когда они находились в Зауральной роще, обвиняемый сперва изнасиловал свою жертву, а затем задушил платком. Тело приятельницы он выкинул на берегу реки Урал. По данным портала Урал56, в ходе допросов 23-летний молодой человек частично признал свою вину. Он признался в убийстве, но отрицал изнасилование. Он сообщил, что убил девушку из-за того, что она его оскорбила. В итоге ему были предъявлены обвинения по по двум статьям: «Убийство, совершенное с целью скрыть другое преступление или облегчить его совершение, сопряженное с изнасилованием» и «Изнасилование». Суд приговорил мужчину к 19 годам колонии строгого режима и 3 млн рублей компенсации морального вреда родственникам убитой девушки. Местные СМИ отмечали, что после оглашения приговора молодой человек стал угрожать расправой адвокату потерпевшей стороны.',\n 'title': 'Изнасиловал и задушил колготками: как приморец отомстил подруге',\n 'summary': 'В Приморском крае правоохранители задержали 24-летнего местного жителя по подозрению в убийстве 17-летней девушки — ее тело было найдено два дня назад в реке Уссури. По данным СМИ, девушка пропала 22 ноября после прогулки с молодым человеком. Известно, что он был влюблен в приятельницу, однако та не отвечала взаимностью. В ходе допросов молодой человек рассказал, что после ссоры он изнасиловал и убил студентку, задушив колготками.',\n 'date': '2019-11-27 12:51:33'}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_records[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['url', 'text', 'title', 'summary', 'date'])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_records[1].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-06-01 10:35:49 - 2019-05-31 23:56:26\n",
      "2019-06-01 08:30:00 - 2019-09-30 23:11:23\n",
      "2019-10-01 08:23:02 - 2020-03-23 22:16:23\n"
     ]
    }
   ],
   "source": [
    "print(min([record[\"date\"] for record in train_records]), end=' - ')\n",
    "print(max([record[\"date\"] for record in train_records]))\n",
    "print(min([record[\"date\"] for record in val_records]), end=' - ')\n",
    "print(max([record[\"date\"] for record in val_records]))\n",
    "print(min([record[\"date\"] for record in test_records]), end=' - ')\n",
    "print(max([record[\"date\"] for record in test_records]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from collections import Counter, namedtuple\n",
    "import razdel\n",
    "import pymorphy2\n",
    "\n",
    "Stats = namedtuple(\"Stats\", \"vocabulary,lemma_vocabulary,words_counts,unique_words_counts\")\n",
    "\n",
    "def collect_stats(records, lower=True, text_max_words=3000, summary_max_words=100, nrows=1000):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    text_stats = Stats(Counter(),  Counter(), list(), list())\n",
    "    summary_stats = Stats(Counter(),  Counter(), list(), list())\n",
    "\n",
    "    def update_record_field_stats(field, stats, max_words):\n",
    "        words = [word.text for word in razdel.tokenize(field)][:max_words]\n",
    "        lemmas = [morph.parse(word)[0].normal_form for word in words]\n",
    "        stats.vocabulary.update(words)\n",
    "        stats.lemma_vocabulary.update(lemmas)\n",
    "        stats.words_counts.append(len(words))\n",
    "        stats.unique_words_counts.append(len(set(words)))\n",
    "\n",
    "    for i, record in enumerate(records):\n",
    "        if i >= nrows:\n",
    "            break\n",
    "        text = record[\"text\"]\n",
    "        text = text if not lower else text.lower()\n",
    "        update_record_field_stats(text, text_stats, text_max_words)\n",
    "\n",
    "        summary = record[\"summary\"]\n",
    "        summary = summary if not lower else summary.lower()\n",
    "        summary_words = [word.text for word in razdel.tokenize(summary)]\n",
    "        update_record_field_stats(summary, summary_stats, summary_max_words)\n",
    "    return text_stats, summary_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train texts vocabulary size:  83571\n",
      "Train texts lemma vocabulary size:  38027\n",
      "Train summaries vocabulary size:  15353\n",
      "Train summaries lemma vocabulary size:  9006\n",
      "Train common lemmas summary vs text:  8668\n"
     ]
    }
   ],
   "source": [
    "train_text_stats, train_summary_stats = collect_stats(train_records)\n",
    "print(\"Train texts vocabulary size: \", len(train_text_stats.vocabulary))\n",
    "print(\"Train texts lemma vocabulary size: \", len(train_text_stats.lemma_vocabulary))\n",
    "print(\"Train summaries vocabulary size: \", len(train_summary_stats.vocabulary))\n",
    "print(\"Train summaries lemma vocabulary size: \", len(train_summary_stats.lemma_vocabulary))\n",
    "print(\"Train common lemmas summary vs text: \", len(set(train_text_stats.lemma_vocabulary.keys()) & set(train_summary_stats.lemma_vocabulary.keys())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 2000x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "axs[0].hist(train_text_stats.words_counts, 20)\n",
    "axs[0].set_title('# Words in texts')\n",
    "\n",
    "axs[1].hist(train_summary_stats.words_counts, 20)\n",
    "axs[1].set_title('# Words in summary')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "\n",
    "def calc_scores(references, predictions, metric=\"all\"):\n",
    "    print(\"Count:\", len(predictions))\n",
    "    print(\"Ref:\", references[-1])\n",
    "    print(\"Hyp:\", predictions[-1])\n",
    "\n",
    "    if metric in (\"bleu\", \"all\"):\n",
    "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
    "    if metric in (\"rouge\", \"all\"):\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(predictions, references, avg=True)\n",
    "        print(\"ROUGE: \", scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1000\n",
      "Ref: пропавшую в ставрополе 16-летнюю школьницу нашли живой. как сообщили в региональном следственном управлении, девушка физически не пострадала и не стала жертвой преступления. по неофициальной информации, она решила сбежать из дома после ссоры с родителями. поиски продолжались более суток, было возбуждено уголовное дело об убийстве после того, как в лесу нашли телефон пропавшей.\n",
      "Hyp: в ставропольском крае спустя более 24 часов поисков нашли 16-летнюю девушку, которая пропала утром в понедельник, 11 ноября. об этом сообщили в региональном управлении мвд. школьницу обнаружили вечером 12 ноября. как написал в своем инстаграме мэр ставрополя андрей джатдоев , «она жива-здорова». в ск рф также подтвердили информацию и отметили, что обстоятельства загадочного исчезновения подростка установят в ходе ее опроса. пока правоохранители не сообщают, почему девушка пропала и где находилась все это время. по предварительным данным, преступлений в отношении нее не совершалось. по неофициальной информации, девочка ушла из дома после ссоры с матерью. telegram-канал life shot со ссылкой на мать пропавшей сообщает, что конфликт произошел из-за оценок школьницы по математике. девочку якобы нашли в подъезде жилого дома недалеко от квартиры, где живет ее семья.\n",
      "BLEU:  0.198874220744119\n",
      "ROUGE:  {'rouge-1': {'f': 0.2340719331401669, 'p': 0.21740420466203236, 'r': 0.3706358098488547}, 'rouge-2': {'f': 0.09708359688734704, 'p': 0.09249331218556182, 'r': 0.15382109499081684}, 'rouge-l': {'f': 0.17972898512655736, 'p': 0.19730861101905142, 'r': 0.34101931869146107}}\n"
     ]
    }
   ],
   "source": [
    "import razdel\n",
    "\n",
    "def calc_lead_n_score(records, n=3, lower=True, nrows=1000):\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for i, record in enumerate(records):\n",
    "        if i >= nrows:\n",
    "            break\n",
    "\n",
    "        summary = record[\"summary\"]\n",
    "        summary = summary if not lower else summary.lower()\n",
    "        references.append(summary)\n",
    "\n",
    "        text = record[\"text\"]\n",
    "        text = text if not lower else text.lower()\n",
    "        sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
    "        prediction = \" \".join(sentences[:n])\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    calc_scores(references, predictions)\n",
    "\n",
    "calc_lead_n_score(test_records, n=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['генеральный', 'прокурор', 'израиль', 'авихай', 'мандельблит', 'предъявить', 'обвинение', 'премьер', 'министр', 'страна', 'биньямин', 'нетаньяху', 'три', 'статья', 'взяточничество', 'мошенничество', 'злоупотребление', 'доверие', 'которые', 'версия', 'следствие', 'совершить', 'как', 'пост', 'глава', 'правительство', 'должность', 'министр', 'связь']\n",
      "['генеральный', 'прокурор', 'израиль', 'авихай', 'мандельблит', 'предъявить', 'обвинение', 'премьер', 'министр', 'страна', 'биньямин', 'нетаньяху', 'три', 'статья', 'взяточничество', 'мошенничество', 'злоупотребление', 'доверие', 'которые', 'версия', 'следствие', 'совершить', 'как', 'пост', 'глава', 'правительство', 'должность', 'министр', 'связь', 'сложный', 'грустный', 'день', 'житель', 'израиль', 'меня', 'принять', 'решение', 'тяжёлый', 'сердце', 'правоохранительный', 'орган', 'занимать', 'ничью', 'политический', 'сторона', 'это', 'правый', 'левый', 'это', 'вопрос', 'политика', 'это', 'верховенство', 'закон', 'демократический', 'государство', 'сказать', 'генпрокурор', 'частность', 'документ', 'содержаться', 'обвинение', 'незаконный', 'получение', 'нетаньяху', 'ценный', 'подарок', 'крупный', 'предприниматель', 'миллиардер', 'австралия', 'джеймс', 'пакер', 'израильский', 'кинопродюсер', 'арнона', 'милчена', 'генпрокурор', 'обратиться', 'кнессет', 'просьба', 'снять', 'неприкосновенность', 'нетаньяху', 'прошлый', 'месяц', 'сообщаться', 'попытка', 'премьер', 'договориться', 'различный', 'издание', 'чтобы', 'журналист', 'писать', 'политика', 'выгодный', 'свет', 'одно', 'обвинение', 'касаться', 'связь', 'премьер', 'владелец', 'крупный', 'израильский', 'телекоммуникационный', 'компания', 'bezeq', 'шауль', 'эловичем', 'нетаньяху', 'мнение', 'прокуратура', 'оказывать', 'преференция', 'эловичу', 'обмен', 'положительный', 'освещение', 'деятельность', 'власть', 'израиль', 'сайт', 'компания', 'сам', 'премьер', 'все', 'отрицать', 'утверждать', 'что', 'расследование', 'инициировать', 'его', 'политический', 'оппонент', 'это', 'израильский', 'сми', 'сообщать', 'что', 'нетаньяху', 'намеренный', 'принять', 'закон', 'получение', 'иммунитет', 'июнь', 'нынешний', 'год', 'стать', 'известный', 'что', 'любовь', 'супруг', 'премьер', 'министр', 'израиль', 'служба', 'доставка', 'еда', 'кейтерингу', 'стоить', 'сара', 'нетаньяху', 'продолжительный', 'судебный', 'разбирательство', 'репутация', 'июнь', 'телерадиокомпания', 'кан', 'сообщить', 'что', 'процесс', 'данному', 'дело', 'быть', 'завершить', 'признание', 'вина', 'сторона', 'ответчица', 'обещание', 'расплатиться', 'долг', 'личный', 'средство', 'жена', 'биньямин', 'нетаньяху', 'платить', 'еда', 'деньга', 'государственный', 'бюджет', 'несколько', 'год', 'потратить', 'образ', '100', 'тысяча', 'следствие', 'подавать', 'иск', 'обвинение', 'мошенничество', 'того', 'как', 'сара', 'нетаньяху', 'заявить', 'готовность', 'сотрудничество', 'прокуратура', 'формулировка', 'изменить', 'преднамеренный', 'использование', 'ошибка', 'другого', 'лицо', 'отличие', 'мошенничество', 'израиль', 'статья', 'предусматривать', 'уголовный', 'ответственность', 'регулироваться', 'как', 'административный', 'правонарушение', 'чужой', 'ошибка', 'стать', 'недочёт', 'работа', 'бухгалтер', 'премьер', 'министр', 'израиль', 'которые', 'знать', 'что', 'штат', 'помощник', 'политик', 'быть', 'персональный', 'шеф', 'повар', 'законодательство', 'страна', 'наличие', 'отдельный', 'повар', 'учреждение', 'иметь', 'право', 'заказывать', 'готовый', 'еда', 'его', 'наличие', 'сара', 'слово', 'знать', 'период', 'сентябрь', '2010', 'март', '2013', 'год', 'адвокат', 'жена', 'премьер', 'договориться', 'выплата', 'средство', 'размер', 'тысяча', 'шекелей', 'тысяча', 'представитель', 'государственный', 'прокурор', 'рассказать', 'что', '60-летняя', 'госпожа', 'нетаньяху', 'должный', 'быть', 'выплатить', 'остаться', 'часть', 'задолженность', 'траншея', 'сумма', 'пять', 'тысяча', 'шекелей', 'новостной', 'портал', 'walla', 'рассказать', 'что', 'случай', 'если', 'возвращение', 'потраченного', 'возникнуть', 'трудность', 'государство', 'мочь', 'подать', 'новый', 'иск', 'гражданский', 'суд', 'слово', 'судья', 'который', 'оглашать', 'приговор', 'процитировать', 'портал', 'times', 'israel', 'самом', 'дело', 'ответчик', 'злоупотреблять', 'государственный', 'средство', 'это', 'суд', 'отметить', 'отсутствие', 'проблема', 'закон', 'сара', 'прошлое', 'подчеркнуть', 'что', 'она', 'признать', 'ответственность', 'чем', 'сэкономить', 'много', 'драгоценный', 'судебный', 'время', 'оглашение', 'вердикт', 'нетаньяху', 'признаться', 'суд', 'том', 'что', 'она', 'пережить', 'запись', 'наличие', 'судимость', 'злоупотребление', 'общественный', 'доверие', 'появиться', 'личный', 'дело', 'сторона', 'обвинение', 'сделать', 'заключение', 'вердикт', 'означать', 'что', 'человек', 'доступ', 'государственный', 'средство', 'занимать', 'должность', 'мочь', 'распоряжаться', 'ими', 'будто', 'они', 'собственность', 'адвокат', 'который', 'представлять', 'нетаньяху', 'заявить', 'что', 'ужасный', 'обстоятельство', 'были', 'направить', 'муж', 'подсудимый', 'правительство', 'это', 'одно', 'самых', 'жестокий', 'болезненный', 'наказание', 'которым', 'практика', 'подвергаться', 'человек', 'подчеркнуть', 'юрист', 'Это', 'результат', 'четыре', 'год', 'ужасный', 'утечка', 'клевета', 'которые', 'попортить', 'кровь', 'клиент', 'они', 'забыть', 'что', 'она', 'все', 'мать', 'жена', 'продолжить', 'стоять', 'потрясение', 'того', 'мочь', 'зайти', 'общество', 'чтобы', 'причинить', 'боль', 'человек', 'никто', 'хотеть', 'навредить', 'миссис', 'нетаньяху', 'цель', 'было', 'ранить', 'муж', 'развалить', 'правительство', 'один', 'сын', 'чета', 'нетаньяху', 'яир', 'попадать', 'скандальный', 'ситуация', 'январь', 'прошлый', 'год', 'израильский', 'сми', 'распространить', 'аудиозапись', 'которой', 'яир', 'спрашивать', 'приятель', 'воспользоваться', 'услуга', 'проститутка', 'даже', 'моральный', 'облик', 'сын', 'премьер', 'вызвать', 'вопрос', 'оппозиция', 'его', 'собеседник', 'быть', 'сын', 'известный', 'израильский', 'предприниматель', 'коби', 'маймона', 'которому', 'яир', 'обратиться', 'слово', 'папа', 'дать', 'возможность', 'отец', 'получить', 'миллиард', 'мне', 'говорить', '400', 'шекелях', 'слово', 'воспринять', 'как', 'косвенный', 'доказательство', 'коррупционный', 'связь', 'премьер', 'министр', 'израиль', 'бизнесмен', 'маймоном', 'речь', 'идти', 'сделка', 'добыча', 'природный', 'газ', 'сам', 'маймон', 'являться', 'акционер', 'энергетический', 'компания', 'isramco', 'яир', 'прийтись', 'извиниться', 'оправдаться', 'тем', 'что', 'быть', 'нетрезвый']\n"
     ]
    }
   ],
   "source": [
    "# Делаем предобработку\n",
    "\n",
    "import razdel\n",
    "import spacy\n",
    "\n",
    "# Список частей речи, которые мы не хотим считать значимыми.\n",
    "# Подбирался на глаз.\n",
    "BAD_POS = (\"PREP\", \"NPRO\", \"CONJ\", \"PRCL\", \"NUMR\", \"PRED\", \"INTJ\", \"PUNCT\", \"CCONJ\", \"ADP\", \"DET\", \"ADV\")\n",
    "\n",
    "# Загрузка модели для частеречной разметки.\n",
    "spacy_model = spacy.load(\"ru_core_news_md\")\n",
    "\n",
    "\n",
    "# Метод для разбиения текста на предложения.\n",
    "def sentenize(text):\n",
    "    return [s.text for s in razdel.sentenize(text)]\n",
    "\n",
    "\n",
    "# Метод для токенизации предложения.\n",
    "def tokenize_sentence(sentence):\n",
    "    sentence = sentence.strip().replace(\"\\xa0\", \"\")\n",
    "    tokens = [token.lemma_ for token in spacy_model(sentence) if token.pos_ not in BAD_POS]\n",
    "    tokens = [token for token in tokens if len(token) > 2]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Метод для токенизации всего текста.\n",
    "def tokenize_text(text):\n",
    "    all_tokens = []\n",
    "    for sentence in sentenize(text):\n",
    "        all_tokens.extend(tokenize_sentence(sentence))\n",
    "    return all_tokens\n",
    "\n",
    "\n",
    "# Пример работы обоих методов.\n",
    "text = test_records[0][\"text\"]\n",
    "sentences = sentenize(text)\n",
    "print(tokenize_sentence(sentences[0]))\n",
    "print(tokenize_text(text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class LuhnSummarizer:\n",
    "    \"\"\"\n",
    "    Метод Луна.\n",
    "    Основано на https://github.com/miso-belica/sumy/blob/main/sumy/summarizers/luhn.py\n",
    "    Оригинальная статья: https://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        significant_percentage = 0.4, # 40% самых частотных токенов мы считаем значимыми.\n",
    "        min_token_freq = 2, # Кроме того, слова должны встречаться минимум 2 раза.\n",
    "        max_gap_size = 4, # Максимальное количество подряд идущих незначимых токенов в промежутках.\n",
    "        verbose = False # Отладочный вывод для наглядности.\n",
    "    ):\n",
    "        self.significant_percentage = significant_percentage\n",
    "        self.min_token_freq = min_token_freq\n",
    "        self.max_gap_size = max_gap_size\n",
    "        self.chunk_ending_mask = [0] * self.max_gap_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __call__(self, text, target_sentences_count):\n",
    "        # Считаем значимые токены.\n",
    "        all_significant_tokens = self._get_significant_tokens(text)\n",
    "        if self.verbose:\n",
    "            print(\"Значимые токены: \", all_significant_tokens)\n",
    "\n",
    "        # Считаем значимости предложений.\n",
    "        ratings = []\n",
    "        for sentence_index, sentence in enumerate(sentenize(text)):\n",
    "            # Значимость предложений - максимум из значимостей промежутков.\n",
    "\n",
    "            sentence_results = self._get_chunk_ratings(sentence, all_significant_tokens)\n",
    "\n",
    "            if not sentence_results:\n",
    "                sentence_results = [0]\n",
    "\n",
    "            sentence_rating = max(sentence_results)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(\"\\tПРЕДЛОЖЕНИЕ. Значимость: {}, текст: {}\".format(sentence_rating, sentence))\n",
    "            ratings.append((sentence_rating, sentence_index))\n",
    "\n",
    "        # Сортируем предложения по значимости.\n",
    "        ratings.sort(reverse=True)\n",
    "\n",
    "        # Оставляем топовые и собираем реферат.\n",
    "        ratings = ratings[:target_sentences_count]\n",
    "        indices = [index for _, index in ratings]\n",
    "        indices.sort()\n",
    "        return \" \".join([sentences[index] for index in indices])\n",
    "\n",
    "    def _get_significant_tokens(self, text):\n",
    "        \"\"\" Метод для подсчёта того, какие токены являются значимыми. \"\"\"\n",
    "        tokens_counter = Counter(tokenize_text(text))\n",
    "        significant_tokens_max_count = int(len(tokens_counter) * self.significant_percentage)\n",
    "        significant_tokens = tokens_counter.most_common(significant_tokens_max_count)\n",
    "        significant_tokens = {token for token, cnt in significant_tokens if cnt >= self.min_token_freq}\n",
    "        return significant_tokens\n",
    "\n",
    "    def _get_chunk_ratings(self, sentence, significant_tokens):\n",
    "        \"\"\" Разбиваем предложение на промежтуки и считаем их значимости. \"\"\"\n",
    "\n",
    "        tokens = tokenize_sentence(sentence)\n",
    "\n",
    "        chunks, masks = [], []\n",
    "        in_chunk = False\n",
    "        for token in tokens:\n",
    "            is_significant_token = token in significant_tokens\n",
    "\n",
    "            if is_significant_token and not in_chunk:\n",
    "                in_chunk = True\n",
    "                masks.append([int(is_significant_token)])\n",
    "                chunks.append([token])\n",
    "            elif in_chunk:\n",
    "                last_mask = masks[-1]\n",
    "                last_mask.append(int(is_significant_token))\n",
    "                last_chunk = chunks[-1]\n",
    "                last_chunk.append(token)\n",
    "            if not chunks:\n",
    "                continue\n",
    "\n",
    "            # Проверяем на наличие 4 подряд идущих незначимых токенов.\n",
    "            # Если встретили - завершаем промежуток.\n",
    "            last_chunk_ending_mask = masks[-1][-self.max_gap_size:]\n",
    "            if last_chunk_ending_mask == self.chunk_ending_mask:\n",
    "                in_chunk = False\n",
    "\n",
    "        ratings = []\n",
    "        for chunk, mask in zip(chunks, masks):\n",
    "            rating = self._get_chunk_rating(mask, chunk)\n",
    "            ratings.append(rating)\n",
    "        return ratings\n",
    "\n",
    "    def _get_chunk_rating(self, original_mask, chunk):\n",
    "        \"\"\" Подсчёт значимости одного промежутка \"\"\"\n",
    "\n",
    "        # Убираем незначимые токены в конце промежутка\n",
    "        original_mask = \"\".join(map(str, original_mask))\n",
    "        mask = original_mask.rstrip(\"0\")\n",
    "\n",
    "        end_index = original_mask.rfind(\"1\") + 1\n",
    "        chunk = chunk[:end_index]\n",
    "        assert len(mask) == len(chunk)\n",
    "        chunk = \" \".join(chunk)\n",
    "\n",
    "        # Считаем значимость\n",
    "        words_count = len(mask)\n",
    "        assert words_count > 0\n",
    "        significant_words_count = mask.count(\"1\")\n",
    "        assert significant_words_count > 0\n",
    "\n",
    "        rating = significant_words_count * significant_words_count / words_count\n",
    "        if self.verbose:\n",
    "            print(\"ПРОМЕЖУТОК. Значимость: {}, маска: {}, текст: {}\".format(rating, mask, chunk))\n",
    "        return rating"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Текст: Генеральный прокурор Израиля Авихай Мандельблит предъявил обвинение премьер-министру страны Биньямину Нетаньяху по трем статьям: взяточничество, мошенничество и злоупотребление доверием, которые он, по версии следствия, совершил как на посту главы правительства, так и в должности министра связи. «Сегодня сложный и грустный день для всех жителей Израиля и для меня лично. Я принял это решение с тяжелым сердцем. Правоохранительные органы не занимают ничью политическую сторону. Это не правые или левые, это не вопрос политики. Это верховенство закона в демократическом государстве», — сказал генпрокурор. В частности, в документе содержится обвинение в незаконном получении Нетаньяху ценных подарков от крупных предпринимателей: миллиардера из Австралии Джеймса Пакера и израильского кинопродюсера Арнона Милчена. Генпрокурор обратился в Кнессет с просьбой снять неприкосновенность с Нетаньяху. В прошлом месяце также сообщалось о попытках премьера договориться с различными изданиями, чтобы журналисты писали о политике в выгодном свете. Одно из обвинений касается связей премьера с владельцем крупнейшей израильской телекоммуникационной компании Bezeq Шаулем Эловичем. Нетаньяху, по мнению прокуратуры, оказывал преференции Эловичу в обмен на положительное освещение деятельности властей Израиля на сайте компании. Сам премьер, впрочем, все отрицает и утверждает, что расследования инициированы его политическими оппонентами. При этом израильские СМИ сообщают, что Нетаньяху намерен принять закон о получении иммунитета. В июне нынешнего года стало известно, что любовь супруги премьер-министра Израиля к службам доставки еды и кейтерингу стоила Саре Нетаньяху продолжительных судебных разбирательств и репутации. 16 июня телерадиокомпания «Кан» сообщила, что процесс по данному делу был завершен после признания вины со стороны ответчицы и обещания расплатиться с долгами из личных средств. Жена Биньямина Нетаньяху платила за еду деньгами из государственного бюджета и за несколько лет потратила таким образом около $100 тысяч. Изначально следствие подавало иск по обвинению в мошенничестве, но после того, как Сара Нетаньяху заявила о готовности к сотрудничеству с прокуратурой , формулировку изменили на «преднамеренное использование ошибки другого лица». В отличие от «мошенничества», в Израиле эта статья не предусматривает уголовную ответственность и регулируется как административное правонарушение. Чужой «ошибкой» стал недочет в работе бухгалтеров премьер-министра Израиля, которые не знали, что в штате помощников политика есть персональный шеф-повар. Согласно законодательству страны, при наличии отдельного повара учреждение не имеет права заказывать готовую еду, а о его наличии Сара, по ее словам, якобы не знала в период с сентября 2010 по март 2013 года. Адвокаты жены премьера договорились о выплате средств в размере 55 тысяч шекелей (около $10 тысяч). Представители государственного прокурора рассказали, что 60-летняя госпожа Нетаньяху должна будет выплатить оставшуюся часть задолженности за 11 траншей — каждый на сумму пять тысяч шекелей. Новостной портал Walla рассказал, что в случае, если с возвращением потраченного возникнут трудности, государство может подать новый иск в гражданский суд. Слова судьи, который оглашал приговор, процитировал портал Times of Israel: «В самом деле, ответчик злоупотреблял государственными средствами». Однако, помимо этого, суд отметил отсутствие каких-либо проблем с законом у Сары в прошлом и подчеркнул, что она «признала свою ответственность, чем сэкономила много драгоценного судебного времени». После оглашения вердикта Нетаньяху призналась суду в том, что она «пережила уже достаточно». Теперь запись о наличии судимости и злоупотреблении общественным доверием появится в ее личном деле. Сторона обвинения сделала свое заключение: «Вердикт означает, что человек с доступом к государственным средствам, независимо от занимаемой им должности, не может распоряжаться ими так, будто они его собственность». Адвокат, который представлял Нетаньяху, заявил, что эти «ужасные обстоятельства» были направлены против мужа подсудимой и его правительства. «Это одно из самых жестоких и болезненных наказаний, которым в моей практике подвергался человек, — подчеркнул юрист. — Это результат четырех лет ужасных утечек и клеветы, которые попортили кровь моего клиента. Они забыли, что она все еще мать и жена». Он продолжил: «Я стоял в потрясении от того, как далеко может зайти наше общество, чтобы причинить боль человеку. И, разумеется, никто не хотел навредить миссис Нетаньяху. Целью было ранить ее мужа и развалить правительство». Один из сыновей четы Нетаньяху — Яир — тоже попадал в скандальные ситуации. В январе прошлого года израильские СМИ распространили аудиозапись, на которой Яир спрашивал у своего приятеля, где можно воспользоваться услугами проституток. Однако даже не моральный облик сына премьера вызвал вопросы оппозиции. Его собеседником был сын известного израильского предпринимателя Коби Маймона, к которому Яир обратился со словами: «Мой папа дал возможность твоему отцу получить 20 миллиардов, и ты мне говоришь о 400 шекелях». Тогда эти слова восприняли как косвенное доказательство коррупционных связей премьер-министра Израиля с бизнесменом Маймоном. Речь идет о сделках по добыче природного газа. Сам Маймон является акционером в энергетической компании Isramco. Впоследствии Яиру пришлось извиниться и оправдаться тем, что он был нетрезв.\n",
      "Итоговый реферат: Генеральный прокурор Израиля Авихай Мандельблит предъявил обвинение премьер-министру страны Биньямину Нетаньяху по трем статьям: взяточничество, мошенничество и злоупотребление доверием, которые он, по версии следствия, совершил как на посту главы правительства, так и в должности министра связи. В июне нынешнего года стало известно, что любовь супруги премьер-министра Израиля к службам доставки еды и кейтерингу стоила Саре Нетаньяху продолжительных судебных разбирательств и репутации. Изначально следствие подавало иск по обвинению в мошенничестве, но после того, как Сара Нетаньяху заявила о готовности к сотрудничеству с прокуратурой , формулировку изменили на «преднамеренное использование ошибки другого лица».\n",
      "Правильный реферат: Премьер-министру Израиля Биньямину Нетаньяху предъявлено обвинение по трем статьям: взяточничество, мошенничество и злоупотребление доверием. Генпрокурор Израиля Авихай Мандельблит подчеркнул, что здесь нет политики, а лишь верховенство закона. Чиновник также обратился в Кнессет с просьбой снять неприкосновенность с Нетаньяху.\n"
     ]
    }
   ],
   "source": [
    "luhn = LuhnSummarizer(verbose=False)\n",
    "summary = luhn(text, 3)\n",
    "print()\n",
    "print(f'Текст: {test_records[0][\"text\"]}')\n",
    "print(f'Итоговый реферат: {summary}')\n",
    "print(f'Правильный реферат: {test_records[0][\"summary\"]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def calc_method_score(records, predict_func, nrows=1000):\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for i, record in enumerate(records):\n",
    "        if nrows is not None and i >= nrows:\n",
    "            break\n",
    "        summary = record[\"summary\"]\n",
    "        text = record[\"text\"]\n",
    "        prediction = predict_func(text, summary)\n",
    "        references.append(summary)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    calc_scores(references, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1000\n",
      "Ref: Пропавшую в Ставрополе 16-летнюю школьницу нашли живой. Как сообщили в региональном следственном управлении, девушка физически не пострадала и не стала жертвой преступления. По неофициальной информации, она решила сбежать из дома после ссоры с родителями. Поиски продолжались более суток, было возбуждено уголовное дело об убийстве после того, как в лесу нашли телефон пропавшей.\n",
      "Hyp: Напомним, 16-летняя девочка пропала по дороге в школу. В Ставропольском крае спустя более 24 часов поисков нашли 16-летнюю девушку, которая пропала утром в понедельник, 11 ноября. Девочку якобы нашли в подъезде жилого дома недалеко от квартиры, где живет ее семья.\n",
      "BLEU:  0.35797099970057833\n",
      "ROUGE:  {'rouge-1': {'f': 0.18276760060764266, 'p': 0.17691218222903127, 'r': 0.20268568406162984}, 'rouge-2': {'f': 0.055436563537828894, 'p': 0.051508483591852484, 'r': 0.06480712005437696}, 'rouge-l': {'f': 0.15682110796300955, 'p': 0.1608378827914166, 'r': 0.18392281992352846}}\n"
     ]
    }
   ],
   "source": [
    "import lexrank\n",
    "from lexrank import LexRank\n",
    "from lexrank.mappings.stopwords import STOPWORDS\n",
    "\n",
    "\n",
    "def predict_lex_rank(text, summary, lxr, summary_size=3, threshold=None):\n",
    "    sentences = [s.text for s in razdel.sentenize(text)]\n",
    "    prediction = lxr.get_summary(sentences, summary_size=summary_size, threshold=threshold)\n",
    "    prediction = \" \".join(prediction)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "sentences = [[s.text for s in razdel.sentenize(r[\"text\"])] for r in test_records]\n",
    "lxr = LexRank(sentences, stopwords=STOPWORDS['ru'])\n",
    "calc_method_score(test_records, lambda x, y: predict_lex_rank(x, y, lxr))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\grayni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1000\n",
      "Ref: Пропавшую в Ставрополе 16-летнюю школьницу нашли живой. Как сообщили в региональном следственном управлении, девушка физически не пострадала и не стала жертвой преступления. По неофициальной информации, она решила сбежать из дома после ссоры с родителями. Поиски продолжались более суток, было возбуждено уголовное дело об убийстве после того, как в лесу нашли телефон пропавшей.\n",
      "Hyp: Telegram-канал Life Shot со ссылкой на мать пропавшей сообщает, что конфликт произошел из-за оценок школьницы по математике. Мать девушки рассказала журналистам, что ее дочь считала олимпиаду важной для получения отличного аттестата и поступления в вуз. Друзья школьницы рассказали «Газете.Ru», что девочка была примерной ученицей и открытым, дружелюбным человеком — у нее ни с кем не было конфликтов.\n",
      "BLEU:  0.28980286094339247\n",
      "ROUGE:  {'rouge-1': {'f': 0.14245001775886856, 'p': 0.11794865764455954, 'r': 0.1882229029421614}, 'rouge-2': {'f': 0.030783787048357956, 'p': 0.025526153539433164, 'r': 0.0409075599287449}, 'rouge-l': {'f': 0.11600953592826965, 'p': 0.10621423268113442, 'r': 0.1696064843153204}}\n"
     ]
    }
   ],
   "source": [
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "import nltk; nltk.download('punkt');\n",
    "\n",
    "\n",
    "def predict_lsa(text, summary, lsa_summarizer, tokenizer, summary_size=3):\n",
    "    parser = PlaintextParser.from_string(text, tokenizer)\n",
    "    predicted_summary = lsa_summarizer(parser.document, summary_size)\n",
    "    predicted_summary = \" \".join([str(s) for s in predicted_summary])\n",
    "    return predicted_summary\n",
    "\n",
    "lsa_summarizer = LsaSummarizer()\n",
    "tokenizer = Tokenizer(\"russian\")\n",
    "calc_method_score(test_records, lambda x, y: predict_lsa(x, y, lsa_summarizer, tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def build_oracle_summary_greedy(text, gold_summary, calc_score, lower=True, max_sentences=30):\n",
    "    '''\n",
    "    Жадное построение oracle summary\n",
    "    '''\n",
    "    gold_summary = gold_summary.lower() if lower else gold_summary\n",
    "    # Делим текст на предложения\n",
    "    sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
    "    n_sentences = len(sentences)\n",
    "    oracle_summary_sentences = set()\n",
    "\n",
    "    score = -1.0\n",
    "    summaries = []\n",
    "    for _ in range(n_sentences):\n",
    "        for i in range(n_sentences):\n",
    "            if i in oracle_summary_sentences:\n",
    "                continue\n",
    "            current_summary_sentences = copy.copy(oracle_summary_sentences)\n",
    "            # Добавляем какое-то предложения к уже существующему summary\n",
    "            current_summary_sentences.add(i)\n",
    "            current_summary = \" \".join([sentences[index] for index in sorted(list(current_summary_sentences))])\n",
    "            # Считаем метрики\n",
    "            current_score = calc_score(current_summary, gold_summary)\n",
    "            summaries.append((current_score, current_summary_sentences))\n",
    "        # Если получилось улучшить метрики с добавлением какого-либо предложения, то пробуем добавить ещё\n",
    "        # Иначе на этом заканчиваем\n",
    "        best_summary_score, best_summary_sentences = max(summaries)\n",
    "        if best_summary_score <= score:\n",
    "            break\n",
    "        oracle_summary_sentences = best_summary_sentences\n",
    "        score = best_summary_score\n",
    "    oracle_summary = \" \".join([sentences[index] for index in sorted(list(oracle_summary_sentences))])\n",
    "    return oracle_summary, oracle_summary_sentences\n",
    "\n",
    "def calc_single_score(pred_summary, gold_summary, rouge):\n",
    "    return rouge.get_scores([pred_summary], [gold_summary], avg=True)['rouge-2']['f']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f3b2ab52ef6444ba22f8c56b498c3b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1000\n",
      "Ref: пропавшую в ставрополе 16-летнюю школьницу нашли живой. как сообщили в региональном следственном управлении, девушка физически не пострадала и не стала жертвой преступления. по неофициальной информации, она решила сбежать из дома после ссоры с родителями. поиски продолжались более суток, было возбуждено уголовное дело об убийстве после того, как в лесу нашли телефон пропавшей.\n",
      "Hyp: об этом сообщили в региональном управлении мвд. по неофициальной информации, девочка ушла из дома после ссоры с матерью. после этого ск рф возбудил уголовное дело об убийстве.\n",
      "BLEU:  0.5342333838390166\n",
      "ROUGE:  {'rouge-1': {'f': 0.36516414259400964, 'p': 0.3969322330404427, 'r': 0.364173753103329}, 'rouge-2': {'f': 0.20398900711669193, 'p': 0.22730701837778183, 'r': 0.2018586399402597}, 'rouge-l': {'f': 0.31884176861033503, 'p': 0.3674352308335014, 'r': 0.3367303938789361}}\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83a6d50285bc4920866898c858eb5ac8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1000\n",
      "Ref: пропавшую в ставрополе 16-летнюю школьницу нашли живой. как сообщили в региональном следственном управлении, девушка физически не пострадала и не стала жертвой преступления. по неофициальной информации, она решила сбежать из дома после ссоры с родителями. поиски продолжались более суток, было возбуждено уголовное дело об убийстве после того, как в лесу нашли телефон пропавшей.\n",
      "Hyp: об этом сообщили в региональном управлении мвд. по неофициальной информации, девочка ушла из дома после ссоры с матерью. после этого ск рф возбудил уголовное дело об убийстве.\n",
      "BLEU:  0.5342333838390166\n",
      "ROUGE:  {'rouge-1': {'f': 0.36516414259400964, 'p': 0.3969322330404427, 'r': 0.364173753103329}, 'rouge-2': {'f': 0.20398900711669193, 'p': 0.22730701837778183, 'r': 0.2018586399402597}, 'rouge-l': {'f': 0.31884176861033503, 'p': 0.3674352308335014, 'r': 0.3367303938789361}}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import razdel\n",
    "\n",
    "def calc_oracle_score(records, nrows=1000, lower=True):\n",
    "    references = []\n",
    "    predictions = []\n",
    "    rouge = Rouge()\n",
    "\n",
    "    for i, record in tqdm(enumerate(records)):\n",
    "        if i >= nrows:\n",
    "            break\n",
    "\n",
    "        summary = record[\"summary\"]\n",
    "        summary = summary if not lower else summary.lower()\n",
    "        references.append(summary)\n",
    "\n",
    "        text = record[\"text\"]\n",
    "        predicted_summary, _ = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge))\n",
    "        predictions.append(predicted_summary)\n",
    "\n",
    "    calc_scores(references, predictions)\n",
    "\n",
    "\n",
    "calc_oracle_score(test_records)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_records)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 url  \\\n0  https://www.gazeta.ru/politics/2019/11/21_a_12...   \n1  https://www.gazeta.ru/army/2019/10/19/12764888...   \n2  https://www.gazeta.ru/social/2019/11/27/128340...   \n\n                                                text  \\\n0  Генеральный прокурор Израиля Авихай Мандельбли...   \n1  Добровольческий батальон «Азов» Национальной г...   \n2  В Приморье по подозрению в убийстве 17-летней ...   \n\n                                               title  \\\n0  Три статьи для премьера: Нетаньяху предъявили ...   \n1  Запрещенный батальон: конгресс США назвал «Азо...   \n2  Изнасиловал и задушил колготками: как приморец...   \n\n                                             summary                 date  \n0  Премьер-министру Израиля Биньямину Нетаньяху п...  2019-11-21 21:45:24  \n1  Конгресс США обратился к Госдепартаменту с тре...  2019-10-19 11:39:07  \n2  В Приморском крае правоохранители задержали 24...  2019-11-27 12:51:33  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>text</th>\n      <th>title</th>\n      <th>summary</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.gazeta.ru/politics/2019/11/21_a_12...</td>\n      <td>Генеральный прокурор Израиля Авихай Мандельбли...</td>\n      <td>Три статьи для премьера: Нетаньяху предъявили ...</td>\n      <td>Премьер-министру Израиля Биньямину Нетаньяху п...</td>\n      <td>2019-11-21 21:45:24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.gazeta.ru/army/2019/10/19/12764888...</td>\n      <td>Добровольческий батальон «Азов» Национальной г...</td>\n      <td>Запрещенный батальон: конгресс США назвал «Азо...</td>\n      <td>Конгресс США обратился к Госдепартаменту с тре...</td>\n      <td>2019-10-19 11:39:07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.gazeta.ru/social/2019/11/27/128340...</td>\n      <td>В Приморье по подозрению в убийстве 17-летней ...</td>\n      <td>Изнасиловал и задушил колготками: как приморец...</td>\n      <td>В Приморском крае правоохранители задержали 24...</td>\n      <td>2019-11-27 12:51:33</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(test_records)\n",
    "df_test[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 url  \\\n0  https://www.gazeta.ru/business/2019/01/24/1214...   \n1  https://www.gazeta.ru/army/2017/10/06/10919768...   \n2  https://www.gazeta.ru/army/2019/01/16/12130555...   \n3  https://www.gazeta.ru/travel/2013/11/08_a_5743...   \n4  https://www.gazeta.ru/business/2018/11/26/1207...   \n\n                                                text  \\\n0  Как сообщают информагентства, в ночь со среды ...   \n1  На сегодняшний день террористы «Исламского гос...   \n2  Сотрудники У ФСБ России по Воронежской области...   \n3  Первым пунктом нашей поездки к морю на автомоб...   \n4  Санкции против России со стороны США и ЕС отпу...   \n\n                                               title  \\\n0  Вину не признал: за что задержан бывший заммин...   \n1  «Стратегия» США заключалась в созерцании насту...   \n2  20 лет без России: как наказали украинского шп...   \n3                                Задержаться в степи   \n4  На этом рынке нас нет: иностранцы боятся вклад...   \n\n                                             summary                 date  \n0  В Москве после допроса задержан Вячеслав Кравч...  2019-01-24 20:18:40  \n1  С момента начала российской военной операции в...  2017-10-06 10:18:24  \n2  Из России выдворили гражданина Украины, которы...  2019-01-16 17:44:49  \n3  Маршрут из Горловки (Донецкая область) к Азовс...  2013-11-13 10:46:49  \n4  Иностранные инвестиции в российскую недвижимос...  2018-11-28 21:10:06  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>text</th>\n      <th>title</th>\n      <th>summary</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.gazeta.ru/business/2019/01/24/1214...</td>\n      <td>Как сообщают информагентства, в ночь со среды ...</td>\n      <td>Вину не признал: за что задержан бывший заммин...</td>\n      <td>В Москве после допроса задержан Вячеслав Кравч...</td>\n      <td>2019-01-24 20:18:40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.gazeta.ru/army/2017/10/06/10919768...</td>\n      <td>На сегодняшний день террористы «Исламского гос...</td>\n      <td>«Стратегия» США заключалась в созерцании насту...</td>\n      <td>С момента начала российской военной операции в...</td>\n      <td>2017-10-06 10:18:24</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.gazeta.ru/army/2019/01/16/12130555...</td>\n      <td>Сотрудники У ФСБ России по Воронежской области...</td>\n      <td>20 лет без России: как наказали украинского шп...</td>\n      <td>Из России выдворили гражданина Украины, которы...</td>\n      <td>2019-01-16 17:44:49</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.gazeta.ru/travel/2013/11/08_a_5743...</td>\n      <td>Первым пунктом нашей поездки к морю на автомоб...</td>\n      <td>Задержаться в степи</td>\n      <td>Маршрут из Горловки (Донецкая область) к Азовс...</td>\n      <td>2013-11-13 10:46:49</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.gazeta.ru/business/2018/11/26/1207...</td>\n      <td>Санкции против России со стороны США и ЕС отпу...</td>\n      <td>На этом рынке нас нет: иностранцы боятся вклад...</td>\n      <td>Иностранные инвестиции в российскую недвижимос...</td>\n      <td>2018-11-28 21:10:06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "0    BOS В Москве после допроса задержан Вячеслав К...\n1    BOS С момента начала российской военной операц...\n2    BOS Из России выдворили гражданина Украины, ко...\n3    BOS Маршрут из Горловки (Донецкая область) к А...\n4    BOS Иностранные инвестиции в российскую недвиж...\nName: summary_clean, dtype: object"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['summary_clean'] = df_train['summary'].apply(lambda v: 'BOS ' + v + ' EOS')\n",
    "df_test['summary_clean'] = df_test['summary'].apply(lambda v: 'BOS ' + v + ' EOS')\n",
    "df_train['summary_clean'][:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "MAX_TRAIN_SAMPLE = 1000\n",
    "MAX_TEST_SAMPLE = 200\n",
    "\n",
    "df_train = df_train[:MAX_TRAIN_SAMPLE]\n",
    "df_test = df_test[:MAX_TEST_SAMPLE]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "max_len_text = 700\n",
    "max_len_sum = 70"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "#tok_text = Tokenizer(oov_token='UNK')\n",
    "tok_text = Tokenizer()\n",
    "tok_text.fit_on_texts(df_train['text'])\n",
    "x_train_tok = tok_text.texts_to_sequences(df_train['text'])\n",
    "x_test_tok = tok_text.texts_to_sequences(df_test['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "text_vocab_size=len(tok_text.word_index)+1\n",
    "\n",
    "padded_x_train = pad_sequences(x_train_tok, maxlen=max_len_text, padding='post', truncating='post')\n",
    "padded_x_test = pad_sequences(x_test_tok, maxlen=max_len_text, padding='post', truncating='post')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "#tok_sum = Tokenizer(oov_token='UNK')\n",
    "tok_sum = Tokenizer()\n",
    "tok_sum.fit_on_texts(df_train['summary_clean'])\n",
    "x_train_sum = tok_sum.texts_to_sequences(df_train['summary_clean'])\n",
    "x_test_sum = tok_sum.texts_to_sequences(df_test['summary_clean'])\n",
    "\n",
    "sum_vocab_size=len(tok_sum.word_index)+1\n",
    "\n",
    "padded_x_train_sum = pad_sequences(x_train_sum, maxlen=max_len_sum, padding='post', truncating='post')\n",
    "padded_x_test_sum = pad_sequences(x_test_sum, maxlen=max_len_sum, padding='post', truncating='post')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 70)"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_x_train_sum.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "reverse_text_index=tok_text.index_word\n",
    "reverse_sum_index=tok_sum.index_word\n",
    "sum_wordindex=tok_sum.word_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, GRU, Embedding, TimeDistributed, Softmax, Dense, RepeatVector, Concatenate, Dense\n",
    "from tensorflow.keras.models import Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 700)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 700, 200)     17745200    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 700, 300),   601200      ['embedding[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 700, 300),   721200      ['lstm[0][0]']                   \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 200)    3111200     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 700, 300),   721200      ['lstm_1[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  601200      ['embedding_1[0][0]',            \n",
      "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 15556)  4682356    ['lstm_3[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,183,556\n",
      "Trainable params: 28,183,556\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 700)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 700, 200)     17745200    ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  [(None, 700, 300),   601200      ['embedding_2[0][0]']            \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  [(None, 700, 300),   721200      ['lstm_4[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, None, 200)    3111200     ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  [(None, 700, 300),   721200      ['lstm_5[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  [(None, None, 300),  601200      ['embedding_3[0][0]',            \n",
      "                                 (None, 300),                     'lstm_6[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_6[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, None, 15556)  4682356    ['lstm_7[0][0]']                 \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,183,556\n",
      "Trainable params: 28,183,556\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 300\n",
    "embedding_dim=200\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_len_text,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(text_vocab_size, embedding_dim, trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,return_state=True,dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) #encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(sum_vocab_size, embedding_dim, trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(sum_vocab_size, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.004)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/lstm_4/while/lstm_cell_4/strided_slice_1' defined at (most recent call last):\n    File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\grayni\\AppData\\Local\\Temp\\ipykernel_28420\\2820238610.py\", line 1, in <module>\n      history = model.fit([padded_x_train, padded_x_train_sum[:,:-1]], padded_x_train_sum.reshape(padded_x_train_sum.shape[0],padded_x_train_sum.shape[1], 1)[:,1:],\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 553, in __call__\n      return super().__call__(inputs, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 625, in call\n      last_output, outputs, states = backend.rnn(\n    File \"C:\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5139, in rnn\n      final_outputs = tf.compat.v1.while_loop(\n    File \"C:\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5118, in _step\n      output, new_states = step_function(\n    File \"C:\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 623, in step\n      return self.cell(inputs, states, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 323, in call\n      c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 250, in _compute_carry_and_output\n      h_tm1_f, self.recurrent_kernel[:, self.units : self.units * 2]\nNode: 'model_1/lstm_4/while/lstm_cell_4/strided_slice_1'\nOOM when allocating tensor with shape[300,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/lstm_4/while/lstm_cell_4/strided_slice_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_141739]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[125], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpadded_x_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadded_x_train_sum\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadded_x_train_sum\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpadded_x_train_sum\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpadded_x_train_sum\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpadded_x_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadded_x_test_sum\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadded_x_test_sum\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpadded_x_test_sum\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadded_x_test_sum\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: Graph execution error:\n\nDetected at node 'model_1/lstm_4/while/lstm_cell_4/strided_slice_1' defined at (most recent call last):\n    File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\grayni\\AppData\\Local\\Temp\\ipykernel_28420\\2820238610.py\", line 1, in <module>\n      history = model.fit([padded_x_train, padded_x_train_sum[:,:-1]], padded_x_train_sum.reshape(padded_x_train_sum.shape[0],padded_x_train_sum.shape[1], 1)[:,1:],\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 553, in __call__\n      return super().__call__(inputs, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 625, in call\n      last_output, outputs, states = backend.rnn(\n    File \"C:\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5139, in rnn\n      final_outputs = tf.compat.v1.while_loop(\n    File \"C:\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5118, in _step\n      output, new_states = step_function(\n    File \"C:\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 623, in step\n      return self.cell(inputs, states, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 323, in call\n      c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 250, in _compute_carry_and_output\n      h_tm1_f, self.recurrent_kernel[:, self.units : self.units * 2]\nNode: 'model_1/lstm_4/while/lstm_cell_4/strided_slice_1'\nOOM when allocating tensor with shape[300,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/lstm_4/while/lstm_cell_4/strided_slice_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_141739]"
     ]
    }
   ],
   "source": [
    "history = model.fit([padded_x_train, padded_x_train_sum[:,:-1]], padded_x_train_sum.reshape(padded_x_train_sum.shape[0],padded_x_train_sum.shape[1], 1)[:,1:],\n",
    "                    epochs=3,\n",
    "                    validation_data=([padded_x_test, padded_x_test_sum[:,:-1]], padded_x_test_sum.reshape(padded_x_test_sum.shape[0], padded_x_test_sum.shape[1], 1)[:,1:]),\n",
    "                    batch_size=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_text, latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = sum_wordindex['bos']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_sum_index[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eos'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eos'  or len(decoded_sentence.split()) >= (max_len_sum - 1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=sum_wordindex['bos']) and i!=sum_wordindex['eos']):\n",
    "            newString=newString+reverse_sum_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_text_index[i]+' '\n",
    "    return newString"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(0, 3):\n",
    "    #print(\"Review:\",seq2text(padded_x_test[i]))\n",
    "    print(\"Original summary:\",seq2summary(padded_x_test_sum[i]))\n",
    "\n",
    "    print(\"Predicted summary:\",decode_sequence(padded_x_test[i].reshape(1, max_len_text)))\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU, AdditiveAttention"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "0      BOS В Москве после допроса задержан Вячеслав К...\n1      BOS С момента начала российской военной операц...\n2      BOS Из России выдворили гражданина Украины, ко...\n3      BOS Маршрут из Горловки (Донецкая область) к А...\n4      BOS Иностранные инвестиции в российскую недвиж...\n                             ...                        \n995    BOS Словакия выслала российского дипломата из-...\n996    BOS На МКС снова сломался туалет. На этот раз ...\n997    BOS В субботу «Интер» и «Рома» сыграют за Супе...\n998    BOS Корпорация Amazon выходит на рынок планшет...\n999    BOS Семь километров — на такую высоту могут за...\nName: summary_clean, Length: 1000, dtype: object"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text'],\n",
    "df_train['summary_clean']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(padded_x_train)\n",
    "BATCH_SIZE = 32\n",
    "steps_per_epoch = len(padded_x_train)//BATCH_SIZE\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((padded_x_train, padded_x_train_sum)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorShape([32, 700]), TensorShape([32, 70]))"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru1 = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.gru2 = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru1(x, initial_state = hidden)\n",
    "        output, state = self.gru2(output, initial_state = state)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "    def call(self, x, query, value):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        #attention_weights = self.attention([ tf.expand_dims(query, 1), value,])\n",
    "        context_vector = self.attention([tf.expand_dims(query, 1), value,])\n",
    "        #context_vector = tf.squeeze(context_vector)\n",
    "\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([context_vector, x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "latent_dim = 300\n",
    "embedding_dim=200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "encoder = Encoder(text_vocab_size, embedding_dim, latent_dim, BATCH_SIZE)\n",
    "decoder = Decoder(sum_vocab_size, embedding_dim, latent_dim, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([sum_wordindex['bos']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_summ_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/decoder/dense_2/MatMul_19/MatMul_1' defined at (most recent call last):\n    File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\grayni\\AppData\\Local\\Temp\\ipykernel_28420\\2570539453.py\", line 10, in <module>\n      batch_loss = train_step(inp, targ, enc_hidden)\n    File \"C:\\Users\\grayni\\AppData\\Local\\Temp\\ipykernel_28420\\2689782007.py\", line 26, in train_step\n      gradients = tape.gradient(loss, variables)\nNode: 'gradient_tape/decoder/dense_2/MatMul_19/MatMul_1'\nOOM when allocating tensor with shape[300,15556] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/decoder/dense_2/MatMul_19/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_step_132756]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[116], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (batch, (inp, targ)) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mtake(steps_per_epoch)):\n\u001B[1;32m---> 10\u001B[0m     batch_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43minp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menc_hidden\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m batch_loss\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m batch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: Graph execution error:\n\nDetected at node 'gradient_tape/decoder/dense_2/MatMul_19/MatMul_1' defined at (most recent call last):\n    File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\grayni\\AppData\\Local\\Temp\\ipykernel_28420\\2570539453.py\", line 10, in <module>\n      batch_loss = train_step(inp, targ, enc_hidden)\n    File \"C:\\Users\\grayni\\AppData\\Local\\Temp\\ipykernel_28420\\2689782007.py\", line 26, in train_step\n      gradients = tape.gradient(loss, variables)\nNode: 'gradient_tape/decoder/dense_2/MatMul_19/MatMul_1'\nOOM when allocating tensor with shape[300,15556] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/decoder/dense_2/MatMul_19/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_step_132756]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "{'в': 1,\n 'bos': 2,\n 'eos': 3,\n 'и': 4,\n 'на': 5,\n 'с': 6,\n 'по': 7,\n 'не': 8,\n 'что': 9,\n 'за': 10,\n '—': 11,\n 'из': 12,\n 'а': 13,\n 'о': 14,\n 'к': 15,\n 'россии': 16,\n 'от': 17,\n 'его': 18,\n 'для': 19,\n 'сша': 20,\n 'но': 21,\n 'как': 22,\n 'после': 23,\n 'до': 24,\n 'года': 25,\n 'он': 26,\n 'это': 27,\n 'может': 28,\n 'во': 29,\n 'также': 30,\n 'у': 31,\n 'будет': 32,\n 'при': 33,\n 'который': 34,\n 'этом': 35,\n 'уже': 36,\n 'году': 37,\n 'президента': 38,\n 'однако': 39,\n 'со': 40,\n 'все': 41,\n 'украины': 42,\n 'лет': 43,\n 'президент': 44,\n 'эксперты': 45,\n 'время': 46,\n 'более': 47,\n 'ее': 48,\n 'их': 49,\n 'был': 50,\n 'заявил': 51,\n 'еще': 52,\n 'против': 53,\n 'об': 54,\n 'только': 55,\n 'москве': 56,\n 'том': 57,\n 'того': 58,\n 'матче': 59,\n 'страны': 60,\n 'считают': 61,\n 'ранее': 62,\n 'стал': 63,\n 'мира': 64,\n 'так': 65,\n '–': 66,\n 'же': 67,\n 'млрд': 68,\n 'словам': 69,\n 'которые': 70,\n 'были': 71,\n 'компании': 72,\n 'будут': 73,\n 'пока': 74,\n 'несколько': 75,\n 'могут': 76,\n 'суд': 77,\n 'власти': 78,\n 'человек': 79,\n 'рф': 80,\n 'своей': 81,\n 'они': 82,\n 'глава': 83,\n 'то': 84,\n 'чемпионата': 85,\n '1': 86,\n 'чтобы': 87,\n 'российский': 88,\n 'под': 89,\n 'млн': 90,\n 'рублей': 91,\n 'данным': 92,\n 'между': 93,\n 'или': 94,\n 'над': 95,\n 'команды': 96,\n 'свою': 97,\n 'без': 98,\n 'раз': 99,\n 'владимир': 100,\n 'ему': 101,\n 'если': 102,\n 'чем': 103,\n 'победу': 104,\n 'своих': 105,\n '2': 106,\n 'два': 107,\n '5': 108,\n 'быть': 109,\n 'российские': 110,\n 'было': 111,\n 'сми': 112,\n 'дело': 113,\n 'дела': 114,\n 'которого': 115,\n 'лиги': 116,\n 'дома': 117,\n 'место': 118,\n 'бывшего': 119,\n 'российской': 120,\n 'российских': 121,\n 'связи': 122,\n 'всего': 123,\n '3': 124,\n 'второй': 125,\n 'она': 126,\n 'александр': 127,\n 'области': 128,\n 'кубка': 129,\n 'день': 130,\n 'жизни': 131,\n 'которая': 132,\n 'россия': 133,\n 'сборная': 134,\n 'через': 135,\n 'тем': 136,\n 'кроме': 137,\n 'решение': 138,\n 'экс': 139,\n 'новый': 140,\n 'считает': 141,\n 'лишь': 142,\n 'этот': 143,\n 'перед': 144,\n 'мнению': 145,\n 'владимира': 146,\n '20': 147,\n 'числе': 148,\n 'работы': 149,\n 'результате': 150,\n 'сборной': 151,\n 'российского': 152,\n 'лидер': 153,\n 'премьер': 154,\n 'тыс': 155,\n 'м': 156,\n 'один': 157,\n '10': 158,\n 'год': 159,\n 'компания': 160,\n 'этого': 161,\n 'своем': 162,\n 'путина': 163,\n 'двух': 164,\n 'даже': 165,\n 'делу': 166,\n 'сергея': 167,\n 'этой': 168,\n 'месте': 169,\n 'своего': 170,\n 'свои': 171,\n 'дмитрий': 172,\n 'первый': 173,\n 'путин': 174,\n 'ни': 175,\n 'стороны': 176,\n 'четыре': 177,\n 'больше': 178,\n '15': 179,\n 'таким': 180,\n 'приговор': 181,\n 'человека': 182,\n 'нового': 183,\n 'детей': 184,\n 'сергей': 185,\n 'цска': 186,\n 'сам': 187,\n 'них': 188,\n 'турнира': 189,\n 'накануне': 190,\n 'когда': 191,\n 'уголовное': 192,\n 'московского': 193,\n 'где': 194,\n 'три': 195,\n 'трамп': 196,\n 'говорят': 197,\n 'москвы': 198,\n 'закон': 199,\n 'безопасности': 200,\n 'была': 201,\n 'есть': 202,\n 'которой': 203,\n 'москва': 204,\n 'первом': 205,\n 'рассказал': 206,\n 'сентября': 207,\n '12': 208,\n 'партии': 209,\n 'погибли': 210,\n '2012': 211,\n 'пять': 212,\n 'мид': 213,\n 'матча': 214,\n 'удалось': 215,\n 'заявили': 216,\n 'серии': 217,\n 'лукашенко': 218,\n 'министр': 219,\n '4': 220,\n 'рынка': 221,\n '6': 222,\n 'стали': 223,\n 'американского': 224,\n 'новых': 225,\n '30': 226,\n 'итогам': 227,\n 'которых': 228,\n 'нет': 229,\n '2018': 230,\n 'порошенко': 231,\n 'именно': 232,\n 'станет': 233,\n 'российская': 234,\n 'александра': 235,\n 'теперь': 236,\n 'правительство': 237,\n 'котором': 238,\n 'впервые': 239,\n 'украине': 240,\n 'группы': 241,\n 'мвд': 242,\n 'новые': 243,\n 'можно': 244,\n 'чего': 245,\n 'сезоне': 246,\n 'россией': 247,\n 'стала': 248,\n 'кто': 249,\n 'франции': 250,\n 'одного': 251,\n 'apple': 252,\n 'сейчас': 253,\n 'евгений': 254,\n 'рамках': 255,\n 'подряд': 256,\n 'представитель': 257,\n 'мария': 258,\n 'службы': 259,\n 'вопрос': 260,\n 'комитет': 261,\n 'россию': 262,\n 'главный': 263,\n 'чемпионов': 264,\n 'одной': 265,\n 'несмотря': 266,\n 'матч': 267,\n 'почти': 268,\n '2011': 269,\n 'признал': 270,\n 'трампа': 271,\n 'придется': 272,\n 'отношении': 273,\n 'санкции': 274,\n 'дтп': 275,\n 'результаты': 276,\n 'фильм': 277,\n 'кино': 278,\n 'благодаря': 279,\n 'рост': 280,\n 'продолжает': 281,\n 'дональд': 282,\n 'свой': 283,\n 'декабря': 284,\n 'стране': 285,\n 'трех': 286,\n 'назад': 287,\n 'пройдет': 288,\n 'вместе': 289,\n 'им': 290,\n 'актер': 291,\n 'алексей': 292,\n 'себя': 293,\n 'города': 294,\n 'киев': 295,\n 'правительства': 296,\n 'федерации': 297,\n 'американский': 298,\n 'свое': 299,\n 'около': 300,\n '11': 301,\n 'всех': 302,\n 'сети': 303,\n 'главы': 304,\n 'хотя': 305,\n 'встречи': 306,\n 'тот': 307,\n 'вторник': 308,\n 'главного': 309,\n 'среди': 310,\n 'министра': 311,\n 'людей': 312,\n 'начала': 313,\n 'европы': 314,\n 'сезона': 315,\n 'экономики': 316,\n 'неделе': 317,\n 'команде': 318,\n 'своим': 319,\n 'следственный': 320,\n '8': 321,\n 'скончался': 322,\n 'суда': 323,\n 'сможет': 324,\n 'действия': 325,\n 'автомобилей': 326,\n 'первой': 327,\n 'чемпионате': 328,\n 'согласно': 329,\n 'возможность': 330,\n 'впрочем': 331,\n '7': 332,\n '9': 333,\n 'момент': 334,\n 'организации': 335,\n 'образом': 336,\n 'меры': 337,\n 'стран': 338,\n 'случае': 339,\n 'ходе': 340,\n 'вновь': 341,\n 'россиянин': 342,\n 'является': 343,\n 'местные': 344,\n 'военных': 345,\n 'раза': 346,\n 'переговоры': 347,\n 'властей': 348,\n 'мая': 349,\n 'права': 350,\n 'бывший': 351,\n 'очень': 352,\n 'украинский': 353,\n 'следствия': 354,\n 'следователи': 355,\n 'подписал': 356,\n 'представители': 357,\n '100': 358,\n 'должен': 359,\n 'дней': 360,\n 'участие': 361,\n 'полузащитник': 362,\n 'конце': 363,\n '2013': 364,\n '14': 365,\n 'которым': 366,\n 'тренер': 367,\n '«зенита»': 368,\n 'цены': 369,\n 'й': 370,\n '18': 371,\n 'отставку': 372,\n 'менее': 373,\n 'самых': 374,\n 'facebook': 375,\n 'бизнес': 376,\n 'вице': 377,\n 'белоруссии': 378,\n 'начале': 379,\n 'ли': 380,\n 'отмечают': 381,\n 'заявила': 382,\n 'аналитики': 383,\n 'очередь': 384,\n 'клуб': 385,\n 'решения': 386,\n 'полиции': 387,\n 'германии': 388,\n 'государства': 389,\n 'сирии': 390,\n 'часов': 391,\n '2014': 392,\n 'стать': 393,\n 'акции': 394,\n 'него': 395,\n 'ей': 396,\n 'го': 397,\n 'поражение': 398,\n 'частности': 399,\n 'часть': 400,\n 'неделю': 401,\n 'поддержку': 402,\n 'выборах': 403,\n 'причиной': 404,\n 'кхл': 405,\n 'последние': 406,\n 'украинского': 407,\n 'тысяч': 408,\n 'убийстве': 409,\n '22': 410,\n 'качестве': 411,\n 'российским': 412,\n 'московский': 413,\n 'лидера': 414,\n 'третий': 415,\n 'турнире': 416,\n 'великобритании': 417,\n 'шарапова': 418,\n 'юрий': 419,\n 'две': 420,\n 'андрей': 421,\n 'прав': 422,\n 'михаил': 423,\n 'внимание': 424,\n 'известно': 425,\n 'выборов': 426,\n 'официально': 427,\n '0': 428,\n 'ввп': 429,\n 'команду': 430,\n 'роста': 431,\n 'одна': 432,\n 'второе': 433,\n '«динамо»': 434,\n '16': 435,\n 'должны': 436,\n 'национальной': 437,\n 'грозит': 438,\n 'бюджета': 439,\n 'рынок': 440,\n 'группе': 441,\n 'условия': 442,\n 'этапе': 443,\n 'экспертов': 444,\n 'выборы': 445,\n 'регионов': 446,\n 'счет': 447,\n 'пост': 448,\n 'свободы': 449,\n 'задержаны': 450,\n 'возрасте': 451,\n 'задержан': 452,\n 'работу': 453,\n 'минобороны': 454,\n 'пор': 455,\n 'территории': 456,\n 'матчей': 457,\n 'тура': 458,\n 'выезде': 459,\n 'италии': 460,\n 'объявил': 461,\n 'собирается': 462,\n 'дмитрия': 463,\n 'iphone': 464,\n 'дел': 465,\n 'ситуации': 466,\n 'чемпион': 467,\n 'поводу': 468,\n '25': 469,\n 'число': 470,\n 'уверены': 471,\n 'населения': 472,\n 'проиграл': 473,\n '19': 474,\n 'победил': 475,\n 'обвинения': 476,\n 'других': 477,\n 'игорь': 478,\n 'москву': 479,\n 'группа': 480,\n 'санкт': 481,\n 'саакашвили': 482,\n 'понедельник': 483,\n 'последних': 484,\n 'нужно': 485,\n 'совета': 486,\n 'убийства': 487,\n 'такое': 488,\n 'месяцев': 489,\n '23': 490,\n 'google': 491,\n 'жителей': 492,\n 'получил': 493,\n 'летний': 494,\n 'павел': 495,\n 'смогут': 496,\n 'третьего': 497,\n 'информации': 498,\n 'премьера': 499,\n 'бизнеса': 500,\n 'обыграла': 501,\n 'которую': 502,\n 'слишком': 503,\n 'политики': 504,\n 'социальной': 505,\n 'одном': 506,\n 'якобы': 507,\n 'закона': 508,\n 'погиб': 509,\n 'добиться': 510,\n 'вскоре': 511,\n 'список': 512,\n '«манчестер': 513,\n 'сыграет': 514,\n 'победы': 515,\n 'киеве': 516,\n 'четверг': 517,\n 'плей': 518,\n 'офф': 519,\n 'возможности': 520,\n 'юлия': 521,\n 'грузии': 522,\n 'минимум': 523,\n 'нато': 524,\n 'бы': 525,\n 'самый': 526,\n 'проект': 527,\n 'истории': 528,\n 'срок': 529,\n 'предлагает': 530,\n 'аварии': 531,\n '»': 532,\n 'клуба': 533,\n 'сторона': 534,\n 'решил': 535,\n 'система': 536,\n 'кремля': 537,\n 'медведева': 538,\n 'ввести': 539,\n 'себе': 540,\n 'регионе': 541,\n 'нападающий': 542,\n 'подозревают': 543,\n 'мошенничестве': 544,\n 'ради': 545,\n 'первое': 546,\n 'сих': 547,\n 'эти': 548,\n 'команда': 549,\n 'шоу': 550,\n 'уступил': 551,\n 'вернуть': 552,\n 'власть': 553,\n 'проблем': 554,\n 'актриса': 555,\n 'скорее': 556,\n 'падение': 557,\n 'встрече': 558,\n 'европе': 559,\n 'автор': 560,\n 'месяц': 561,\n 'правам': 562,\n 'михаила': 563,\n 'прошлом': 564,\n 'поскольку': 565,\n 'управления': 566,\n 'россияне': 567,\n 'россиян': 568,\n 'воскресенье': 569,\n 'много': 570,\n 'утверждают': 571,\n 'информацию': 572,\n 'денег': 573,\n 'доме': 574,\n 'пятницу': 575,\n 'про': 576,\n 'российском': 577,\n 'американских': 578,\n 'смогли': 579,\n 'ближайшее': 580,\n 'самой': 581,\n 'американской': 582,\n 'николай': 583,\n 'полагают': 584,\n 'петербурга': 585,\n 'колонии': 586,\n 'режима': 587,\n 'стало': 588,\n 'виде': 589,\n 'центре': 590,\n 'сериала': 591,\n 'провести': 592,\n 'сделать': 593,\n 'обороны': 594,\n 'последний': 595,\n 'первого': 596,\n 'руководство': 597,\n 'комитета': 598,\n 'последнее': 599,\n 'спорта': 600,\n 'подчеркнул': 601,\n 'защитник': 602,\n 'призвал': 603,\n 'компаний': 604,\n 'марта': 605,\n 'течение': 606,\n 'пройдут': 607,\n 'втором': 608,\n 'новой': 609,\n 'одну': 610,\n 'расходы': 611,\n 'ждут': 612,\n 'отношений': 613,\n 'гран': 614,\n 'виталий': 615,\n 'участников': 616,\n 'пообещал': 617,\n 'сына': 618,\n 'прокуратура': 619,\n 'скандал': 620,\n 'журналисты': 621,\n 'режиссер': 622,\n 'фильма': 623,\n 'имени': 624,\n 'поле': 625,\n 'водитель': 626,\n 'финала': 627,\n 'украину': 628,\n 'января': 629,\n 'отметил': 630,\n 'южной': 631,\n 'факту': 632,\n 'смерти': 633,\n 'украина': 634,\n 'годам': 635,\n 'главе': 636,\n 'алексея': 637,\n 'столице': 638,\n 'сотрудники': 639,\n 'интернет': 640,\n 'мир': 641,\n 'законопроект': 642,\n '50': 643,\n 'я': 644,\n 'безопасность': 645,\n 'местных': 646,\n 'ситуацию': 647,\n 'оппозиции': 648,\n 'футболу': 649,\n 'собой': 650,\n 'сообщают': 651,\n 'счетом': 652,\n 'времени': 653,\n 'такой': 654,\n 'море': 655,\n 'инвесторы': 656,\n 'хотят': 657,\n 'утверждает': 658,\n 'американская': 659,\n 'корпорация': 660,\n 'следует': 661,\n 'выходные': 662,\n 'почему': 663,\n 'обещает': 664,\n 'команд': 665,\n 'ряд': 666,\n 'такие': 667,\n 'те': 668,\n 'ним': 669,\n 'прежнему': 670,\n 'сразу': 671,\n 'спортсмен': 672,\n 'первую': 673,\n 'судья': 674,\n 'новую': 675,\n 'меньше': 676,\n 'рынке': 677,\n 'ким': 678,\n 'отец': 679,\n 'выступил': 680,\n 'количество': 681,\n 'там': 682,\n 'принес': 683,\n 'евро': 684,\n 'петр': 685,\n 'официальный': 686,\n 'насилия': 687,\n 'версии': 688,\n '21': 689,\n 'контракт': 690,\n 'заявления': 691,\n 'конца': 692,\n 'крым': 693,\n 'имеет': 694,\n '400': 695,\n 'недвижимости': 696,\n 'сами': 697,\n 'ниже': 698,\n 'средства': 699,\n 'оон': 700,\n 'представителями': 701,\n 'проведет': 702,\n 'артист': 703,\n 'дал': 704,\n 'пяти': 705,\n 'ночь': 706,\n 'ответ': 707,\n 'нарушений': 708,\n 'договора': 709,\n 'продолжают': 710,\n 'туре': 711,\n 'ворота': 712,\n 'президенту': 713,\n 'выразил': 714,\n 'кнр': 715,\n 'сообщил': 716,\n 'недели': 717,\n 'работе': 718,\n 'расследования': 719,\n 'нхл': 720,\n 'лучше': 721,\n 'апреля': 722,\n 'эта': 723,\n 'погибших': 724,\n 'счету': 725,\n 'августа': 726,\n '13': 727,\n 'военно': 728,\n 'машин': 729,\n 'лидеры': 730,\n '500': 731,\n 'граждан': 732,\n 'инвесторов': 733,\n 'белого': 734,\n 'президентом': 735,\n 'объем': 736,\n 'четвертый': 737,\n 'украинских': 738,\n 'фас': 739,\n 'целом': 740,\n 'выход': 741,\n 'участия': 742,\n 'данных': 743,\n 'пилот': 744,\n 'вторую': 745,\n 'петров': 746,\n 'говорится': 747,\n 'октября': 748,\n 'объявила': 749,\n 'инцидента': 750,\n 'депутат': 751,\n 'намерена': 752,\n 'поражения': 753,\n 'бокс': 754,\n 'офис': 755,\n 'выиграла': 756,\n 'причем': 757,\n 'сообщили': 758,\n 'метров': 759,\n 'попросил': 760,\n 'третьем': 761,\n 'войны': 762,\n 'появилась': 763,\n 'предстоит': 764,\n 'состоится': 765,\n 'военные': 766,\n 'павла': 767,\n 'вышел': 768,\n 'церкви': 769,\n 'причина': 770,\n 'снижение': 771,\n 'нашли': 772,\n 'тренера': 773,\n 'прокат': 774,\n 'госдумы': 775,\n 'возбуждено': 776,\n 'готовы': 777,\n 'граждане': 778,\n 'газ': 779,\n '«газпрома»': 780,\n 'деньги': 781,\n 'нефть': 782,\n 'должна': 783,\n 'эту': 784,\n 'план': 785,\n 'вышла': 786,\n 'районе': 787,\n 'составе': 788,\n 'операции': 789,\n '90': 790,\n 'поэтому': 791,\n 'уголовного': 792,\n 'годом': 793,\n 'процесс': 794,\n 'заседание': 795,\n 'топ': 796,\n 'юрия': 797,\n 'переиграл': 798,\n 'никаких': 799,\n 'будущего': 800,\n 'нескольких': 801,\n 'отказ': 802,\n 'обвиняют': 803,\n 'органов': 804,\n '31': 805,\n 'евгения': 806,\n 'очередной': 807,\n 'оказался': 808,\n 'указ': 809,\n 'владимиром': 810,\n 'полиция': 811,\n 'пострадали': 812,\n 'назначен': 813,\n 'борьбе': 814,\n 'каддафи': 815,\n 'позицию': 816,\n '28': 817,\n 'рулем': 818,\n 'дня': 819,\n 'самом': 820,\n 'леонид': 821,\n 'отношения': 822,\n 'сообщается': 823,\n 'договор': 824,\n 'шесть': 825,\n 'виновным': 826,\n 'тоже': 827,\n 'фоне': 828,\n 'денис': 829,\n 'меркель': 830,\n 'предложение': 831,\n 'переговоров': 832,\n 'места': 833,\n 'администрации': 834,\n 'газа': 835,\n 'мчс': 836,\n 'борьбы': 837,\n '«анжи»': 838,\n 'машины': 839,\n 'метро': 840,\n 'объясняют': 841,\n 'юлии': 842,\n 'тимошенко': 843,\n 'самым': 844,\n 'ipad': 845,\n 'развития': 846,\n 'игроков': 847,\n 'ближайшие': 848,\n 'этапа': 849,\n 'медведев': 850,\n 'следующего': 851,\n 'виктора': 852,\n 'сборную': 853,\n 'намерен': 854,\n '2015': 855,\n 'экономического': 856,\n 'кризиса': 857,\n 'включая': 858,\n 'верят': 859,\n 'сезон': 860,\n 'историю': 861,\n 'дать': 862,\n 'чиновников': 863,\n 'нее': 864,\n 'такую': 865,\n 'участники': 866,\n 'увеличить': 867,\n 'принято': 868,\n 'давления': 869,\n 'вариант': 870,\n 'приняли': 871,\n 'специалисты': 872,\n 'сеть': 873,\n 'десять': 874,\n 'спортсмена': 875,\n 'травмы': 876,\n 'вокруг': 877,\n 'издания': 878,\n 'американские': 879,\n '27': 880,\n 'одним': 881,\n 'временно': 882,\n 'форвард': 883,\n 'стадии': 884,\n 'героем': 885,\n 'следствие': 886,\n '26': 887,\n 'лидеров': 888,\n 'всю': 889,\n 'вот': 890,\n 'рассказала': 891,\n 'ведомства': 892,\n 'суде': 893,\n 'прокурор': 894,\n 'августе': 895,\n 'банк': 896,\n 'украинские': 897,\n 'президенты': 898,\n 'футболиста': 899,\n 'роман': 900,\n 'выиграл': 901,\n 'верховной': 902,\n 'вовсе': 903,\n 'столицы': 904,\n 'поединке': 905,\n 'выхода': 906,\n 'избежать': 907,\n 'посту': 908,\n '2020': 909,\n 'полностью': 910,\n 'порядка': 911,\n 'начал': 912,\n 'шансы': 913,\n 'оказались': 914,\n 'очков': 915,\n 'санкций': 916,\n 'нефти': 917,\n 'татьяна': 918,\n 'испании': 919,\n 'свет': 920,\n 'преступления': 921,\n 'лиц': 922,\n 'главных': 923,\n 'канал': 924,\n 'ольга': 925,\n 'лишения': 926,\n '«локомотив»': 927,\n 'политика': 928,\n 'регулярного': 929,\n 'провел': 930,\n 'дубль': 931,\n 'игры': 932,\n 'директор': 933,\n 'вничью': 934,\n 'решили': 935,\n 'страну': 936,\n 'стартует': 937,\n 'карьеру': 938,\n 'месяца': 939,\n 'которому': 940,\n 'семьи': 941,\n 'вместо': 942,\n 'романа': 943,\n 'цель': 944,\n 'членов': 945,\n 'нарушения': 946,\n '«спартака»': 947,\n 'представителей': 948,\n 'матчи': 949,\n 'останется': 950,\n 'гонке': 951,\n 'пресс': 952,\n 'квартире': 953,\n 'сотрудников': 954,\n 'привести': 955,\n 'андрея': 956,\n 'ведомстве': 957,\n 'чиновника': 958,\n 'ответили': 959,\n 'слова': 960,\n 'данные': 961,\n 'крыму': 962,\n 'своими': 963,\n 'адвокат': 964,\n 'новое': 965,\n 'претензий': 966,\n 'сыграют': 967,\n 'возможно': 968,\n 'завершился': 969,\n 'этап': 970,\n 'игроки': 971,\n '«бавария»': 972,\n 'гостях': 973,\n 'круге': 974,\n 'например': 975,\n 'показали': 976,\n 'китай': 977,\n 'дом': 978,\n 'наиболее': 979,\n 'легендарного': 980,\n 'набрал': 981,\n 'the': 982,\n 'восточной': 983,\n 'производство': 984,\n 'уголовных': 985,\n 'версию': 986,\n 'следующей': 987,\n 'совет': 988,\n 'доклад': 989,\n 'супруга': 990,\n 'политику': 991,\n 'доказать': 992,\n 'жертв': 993,\n 'подготовке': 994,\n 'подопечные': 995,\n 'адвоката': 996,\n 'днр': 997,\n 'путиным': 998,\n 'помощь': 999,\n 'потерпел': 1000,\n ...}"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_sum.word_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    inputs = [tok_text.word_index[i] for i in sentence.split(' ') if i !='']\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_len_text,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, latent_dim))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([tok_sum.word_index['bos']], 0)\n",
    "\n",
    "    for t in range(max_len_sum):\n",
    "        predictions, dec_hidden = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += tok_sum.index_word[predicted_id] + ' '\n",
    "\n",
    "        if tok_sum.index_word[predicted_id] == 'eos':\n",
    "            return result, sentence\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "def summ(sentence):\n",
    "    result, sentence = evaluate(sentence)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq2text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[120], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m6\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     text2 \u001B[38;5;241m=\u001B[39m \u001B[43mseq2text\u001B[49m(padded_x_test[i])\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;66;03m#print(\"Review:\",seq2text(padded_x_test[i]))\u001B[39;00m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOriginal summary:\u001B[39m\u001B[38;5;124m\"\u001B[39m, seq2summary(padded_x_test_sum[i]))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'seq2text' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(3, 6):\n",
    "    text2 = seq2text(padded_x_test[i])\n",
    "    #print(\"Review:\",seq2text(padded_x_test[i]))\n",
    "    print(\"Original summary:\", seq2summary(padded_x_test_sum[i]))\n",
    "    print(\"Predicted summary: \", summ(text2.strip()))\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}