{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"cointegrated/rubert-tiny\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4809\n"
     ]
    }
   ],
   "source": [
    "from corus import load_rudrec\n",
    "\n",
    "json_path = 'data/rudrec_annotated.json'\n",
    "\n",
    "drugs = list(load_rudrec(json_path))\n",
    "print(len(drugs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "RuDReCRecord(\n    file_name='172744.tsv',\n    text='–Ω–∞–º –ø—Ä–æ–ø–∏—Å–∞–ª–∏, —Ç–∞–∫ –º–æ–π —Ä–µ–±–µ–Ω–æ–∫ —Å—ã–ø—å—é –ø–æ–∫—Ä—ã–ª—Å—è, –≥–ª–∞–∑–∞ –æ–ø—É—Ö–ª–∏, —Å–≤–µ—Ä—Ö—É –∏ —Å–Ω–∏–∑—É –Ω–∞ –≤–µ–∫–∞—Ö –≤—ã—Å—ã–ø–∞–ª–∞ —Å—ã–ø—å, ( 8 –º–µ—Å—è—Ü–µ–≤ —Å—ã–Ω—É)–ê –æ—Ç –≤–∏—Ñ–µ—Ä–æ–Ω–∞ —Ç–∞–∫–æ–≥–æ –Ω–µ –±—ã–ª–æ... –£ –∫–æ–≥–æ –µ—â—ë —Ç–∞–∫–∏–µ –ø–æ–±–æ—á–∫–∏, –æ—Ç–∑–æ–≤–∏—Ç–µ—Å—å!1 –ß–µ–º —Å–ø–∞—Å–∞–ª–∏—Å—å?\\n',\n    sentence_id=0,\n    entities=[RuDReCEntity(\n         entity_id='*[0]_se',\n         entity_text='–≤–∏—Ñ–µ—Ä–æ–Ω–∞',\n         entity_type='Drugform',\n         start=122,\n         end=130,\n         concept_id='C0021735',\n         concept_name=nan\n     ),\n     RuDReCEntity(\n         entity_id='*[1]',\n         entity_text='—Å—ã–ø—å—é –ø–æ–∫—Ä—ã–ª—Å—è',\n         entity_type='ADR',\n         start=31,\n         end=45,\n         concept_id='C0015230',\n         concept_name=nan\n     ),\n     RuDReCEntity(\n         entity_id='*[2]',\n         entity_text='–≥–ª–∞–∑–∞ –æ–ø—É—Ö–ª–∏',\n         entity_type='ADR',\n         start=47,\n         end=59,\n         concept_id='C4760994',\n         concept_name=nan\n     ),\n     RuDReCEntity(\n         entity_id='*[3]',\n         entity_text='–Ω–∞ –≤–µ–∫–∞—Ö –≤—ã—Å—ã–ø–∞–ª–∞ —Å—ã–ø—å',\n         entity_type='ADR',\n         start=76,\n         end=98,\n         concept_id='C0015230',\n         concept_name=nan\n     )]\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DI 1401\n",
      "[('–ø—Ä–æ—Å—Ç—É–¥—ã', 64), ('–û–†–í–ò', 47), ('–ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∏', 42)]\n",
      "Drugname 1043\n",
      "[('–í–∏—Ñ–µ—Ä–æ–Ω', 33), ('–ê–Ω–∞—Ñ–µ—Ä–æ–Ω', 25), ('–¶–∏–∫–ª–æ—Ñ–µ—Ä–æ–Ω', 24)]\n",
      "Drugform 836\n",
      "[('—Ç–∞–±–ª–µ—Ç–∫–∏', 154), ('—Ç–∞–±–ª–µ—Ç–æ–∫', 79), ('—Å–≤–µ—á–∏', 63)]\n",
      "ADR 720\n",
      "[('–∞–ª–ª–µ—Ä–≥–∏—è', 16), ('—Å–ª–∞–±–æ—Å—Ç—å', 13), ('–¥–∏–∞—Ä–µ—è', 12)]\n",
      "Drugclass 330\n",
      "[('–ø—Ä–æ—Ç–∏–≤–æ–≤–∏—Ä—É—Å–Ω—ã–π', 21), ('–ø—Ä–æ—Ç–∏–≤–æ–≤–∏—Ä—É—Å–Ω–æ–µ', 18), ('–ø—Ä–æ—Ç–∏–≤–æ–≤–∏—Ä—É—Å–Ω—ã—Ö', 13)]\n",
      "Finding 236\n",
      "[('–∞–ª–ª–µ—Ä–≥–∏–∏', 12), ('—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã', 6), ('—Å–æ–Ω–ª–∏–≤–æ—Å—Ç–∏', 5)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "type2text = defaultdict(Counter)\n",
    "ents = Counter()\n",
    "for item in drugs:\n",
    "    for e in item.entities:\n",
    "        ents[e.entity_type] += 1\n",
    "        type2text[e.entity_type][e.entity_text] += 1\n",
    "\n",
    "for k, v in ents.most_common():\n",
    "    print(k, v)\n",
    "    print(type2text[k].most_common(3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'–Ω–∞–º –ø—Ä–æ–ø–∏—Å–∞–ª–∏, —Ç–∞–∫ –º–æ–π —Ä–µ–±–µ–Ω–æ–∫ —Å—ã–ø—å—é –ø–æ–∫—Ä—ã–ª—Å—è, –≥–ª–∞–∑–∞ –æ–ø—É—Ö–ª–∏, —Å–≤–µ—Ä—Ö—É –∏ —Å–Ω–∏–∑—É –Ω–∞ –≤–µ–∫–∞—Ö –≤—ã—Å—ã–ø–∞–ª–∞ —Å—ã–ø—å, ( 8 –º–µ—Å—è—Ü–µ–≤ —Å—ã–Ω—É)–ê –æ—Ç –≤–∏—Ñ–µ—Ä–æ–Ω–∞ —Ç–∞–∫–æ–≥–æ –Ω–µ –±—ã–ª–æ... –£ –∫–æ–≥–æ –µ—â—ë —Ç–∞–∫–∏–µ –ø–æ–±–æ—á–∫–∏, –æ—Ç–∑–æ–≤–∏—Ç–µ—Å—å!1 –ß–µ–º —Å–ø–∞—Å–∞–ª–∏—Å—å?\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs[0].text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from razdel import tokenize\n",
    "\n",
    "def extract_labels(item):\n",
    "    raw_toks = list(tokenize(item.text))\n",
    "    words = [tok.text for tok in raw_toks]\n",
    "    word_labels = ['O'] * len(raw_toks)\n",
    "    char2word = [None] * len(item.text)\n",
    "    for i, word in enumerate(raw_toks):\n",
    "        char2word[word.start:word.stop] = [i] * len(word.text)\n",
    "\n",
    "    for e in item.entities:\n",
    "        e_words = sorted({idx for idx in char2word[e.start:e.end] if idx is not None})\n",
    "        word_labels[e_words[0]] = 'B-' + e.entity_type\n",
    "        for idx in e_words[1:]:\n",
    "            word_labels[idx] = 'I-' + e.entity_type\n",
    "\n",
    "    return {'tokens': words, 'tags': word_labels}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['–Ω–∞–º', '–ø—Ä–æ–ø–∏—Å–∞–ª–∏', ',', '—Ç–∞–∫', '–º–æ–π', '—Ä–µ–±–µ–Ω–æ–∫', '—Å—ã–ø—å—é', '–ø–æ–∫—Ä—ã–ª—Å—è', ',', '–≥–ª–∞–∑–∞', '–æ–ø—É—Ö–ª–∏', ',', '—Å–≤–µ—Ä—Ö—É', '–∏', '—Å–Ω–∏–∑—É', '–Ω–∞', '–≤–µ–∫–∞—Ö', '–≤—ã—Å—ã–ø–∞–ª–∞', '—Å—ã–ø—å', ',', '(', '8', '–º–µ—Å—è—Ü–µ–≤', '—Å—ã–Ω—É', ')', '–ê', '–æ—Ç', '–≤–∏—Ñ–µ—Ä–æ–Ω–∞', '—Ç–∞–∫–æ–≥–æ', '–Ω–µ', '–±—ã–ª–æ', '...', '–£', '–∫–æ–≥–æ', '–µ—â—ë', '—Ç–∞–∫–∏–µ', '–ø–æ–±–æ—á–∫–∏', ',', '–æ—Ç–∑–æ–≤–∏—Ç–µ—Å—å', '!', '1', '–ß–µ–º', '—Å–ø–∞—Å–∞–ª–∏—Å—å', '?'], 'tags': ['O', 'O', 'O', 'O', 'O', 'O', 'B-ADR', 'I-ADR', 'O', 'B-ADR', 'I-ADR', 'O', 'O', 'O', 'O', 'B-ADR', 'I-ADR', 'I-ADR', 'I-ADR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Drugform', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "print(extract_labels(drugs[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ner_data = [extract_labels(item) for item in drugs]\n",
    "ner_train, ner_test = train_test_split(ner_data, test_size=0.1, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                                                   tokens  \\\n796                                                                   [–ò, —Å–µ–π—á–∞—Å, –Ω–∞–º, —É–∂–µ, 7, –º–µ—Å—è—Ü–µ–≤, ,, –∞–ª–ª–µ—Ä–≥–∏–∏, –Ω–∏, –Ω–∞, —á—Ç–æ, –Ω–µ—Ç, .]   \n2339                                            [¬´, –ù–∞, –¥—É—Ä–∞–∫–∞, –Ω–µ, –Ω—É–∂–µ–Ω, –Ω–æ–∂, ,, –µ–º—É, —Å, —Ç—Ä–∏, –∫–æ—Ä–æ–±–∞, –Ω–∞–≤—Ä–µ—à—å, ‚Ä¶, ¬ª, –ü–æ–º–Ω–∏—Ç–µ, –ø–µ—Å–Ω—é, ?]   \n1672  [–í–∑—è–ª–∞, —Ä–µ–±–µ–Ω–∫—É, –¥–ª—è, —É–∫—Ä–µ–ø–ª–µ–Ω–∏—è, –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞, ..., —Ç, ., –∫, –Ω–∞–º, –µ–≥–æ, –ø–µ–¥–∏–∞—Ç—Ä, –ø–æ—Å–æ–≤–µ—Ç–æ–≤–∞–ª–∞, ,, –¥–∞–∂–µ, –Ω–∞, –≤–∫—É—Å, –Ω–µ, –ø–æ–ø—Ä–æ–±–æ–≤–∞–ª–∞, .]   \n\n                                                                    tags  \n796                      [O, O, O, O, O, O, O, B-Finding, O, O, O, O, O]  \n2339                 [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n1672  [O, O, O, B-DI, I-DI, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>796</th>\n      <td>[–ò, —Å–µ–π—á–∞—Å, –Ω–∞–º, —É–∂–µ, 7, –º–µ—Å—è—Ü–µ–≤, ,, –∞–ª–ª–µ—Ä–≥–∏–∏, –Ω–∏, –Ω–∞, —á—Ç–æ, –Ω–µ—Ç, .]</td>\n      <td>[O, O, O, O, O, O, O, B-Finding, O, O, O, O, O]</td>\n    </tr>\n    <tr>\n      <th>2339</th>\n      <td>[¬´, –ù–∞, –¥—É—Ä–∞–∫–∞, –Ω–µ, –Ω—É–∂–µ–Ω, –Ω–æ–∂, ,, –µ–º—É, —Å, —Ç—Ä–∏, –∫–æ—Ä–æ–±–∞, –Ω–∞–≤—Ä–µ—à—å, ‚Ä¶, ¬ª, –ü–æ–º–Ω–∏—Ç–µ, –ø–µ—Å–Ω—é, ?]</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n    </tr>\n    <tr>\n      <th>1672</th>\n      <td>[–í–∑—è–ª–∞, —Ä–µ–±–µ–Ω–∫—É, –¥–ª—è, —É–∫—Ä–µ–ø–ª–µ–Ω–∏—è, –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞, ..., —Ç, ., –∫, –Ω–∞–º, –µ–≥–æ, –ø–µ–¥–∏–∞—Ç—Ä, –ø–æ—Å–æ–≤–µ—Ç–æ–≤–∞–ª–∞, ,, –¥–∞–∂–µ, –Ω–∞, –≤–∫—É—Å, –Ω–µ, –ø–æ–ø—Ä–æ–±–æ–≤–∞–ª–∞, .]</td>\n      <td>[O, O, O, B-DI, I-DI, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 300\n",
    "pd.DataFrame(ner_train).sample(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['O',\n 'B-ADR',\n 'B-DI',\n 'B-Drugclass',\n 'B-Drugform',\n 'B-Drugname',\n 'B-Finding',\n 'I-ADR',\n 'I-DI',\n 'I-Drugclass',\n 'I-Drugform',\n 'I-Drugname',\n 'I-Finding']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = sorted({label for item in ner_train for label in item['tags']})\n",
    "if 'O' in label_list:\n",
    "    label_list.remove('O')\n",
    "    label_list = ['O'] + label_list\n",
    "label_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 4328\n    })\n    test: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 481\n    })\n})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_data = DatasetDict({\n",
    "    'train': Dataset.from_pandas(pd.DataFrame(ner_train)),\n",
    "    'test': Dataset.from_pandas(pd.DataFrame(ner_test))\n",
    "})\n",
    "ner_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/341 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88210bd62df14e94b3c8e0e249b8ef90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba7db5868ecf46009934dcec0b542027"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/241k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2a0232575c948a18fbd7df598de41d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/468k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0252277519db45a1bf6c56f0c955343a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ef6f559e1aa4c2b9579970fbde2ce14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 9944, 16, 881, 550, 835, 15503, 5, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]} \n",
      "\n",
      "['Hello', ',', 'this', 'is', 'one', 'sentence', '!'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input_ids': [2, 9944, 16, 881, 550, 835, 15503, 7440, 996, 6301, 18, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show ids\n",
    "sentence = \"Hello, this is one sentence!\"\n",
    "print(tokenizer(sentence), '\\n')\n",
    "\n",
    "# show list of words\n",
    "tokens1 = tokenizer.tokenize(sentence)\n",
    "print(tokens1, '\\n')\n",
    "\n",
    "# show ids of the list of words\n",
    "tokens2 = [\"Hello\", \",\", \"this\", \"is\", \"one\", \"sentence\", \"split\", \"into\", \"words\", \".\"]\n",
    "tokenizer(tokens2, is_split_into_words=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–≠—Ç–∏–º', '—Å—Ä–µ–¥—Å—Ç–≤–æ–º', '—è–≤–ª—è–µ—Ç—Å—è', '\"', '–ê–º–∏–∑–æ–Ω', '\"', ',', '–∫–æ—Ç–æ—Ä–æ–µ', '—Ö–æ—Ä–æ—à–æ', '–ø—Ä–æ—Ä–µ–∫–ª–∞–º–∏—Ä–æ–≤–∞–Ω–æ', ',', '–æ–¥–Ω–∞–∫–æ', '—Ç–∞–∫–æ–≥–æ', '—ç—Ñ—Ñ–µ–∫—Ç–∞', '–∫–∞–∫', '–≥–æ–≤–æ—Ä—è—Ç', '–Ω–µ—Ç', '.']\n"
     ]
    }
   ],
   "source": [
    "example = ner_train[5]\n",
    "print(example[\"tokens\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '–≠—Ç–∏', '##–º', '—Å—Ä–µ–¥—Å—Ç–≤–æ', '##–º', '—è–≤–ª—è–µ—Ç—Å—è', '\"', '–ê', '##–º–∏', '##–∑–æ–Ω', '\"', ',', '–∫–æ—Ç–æ—Ä–æ–µ', '—Ö–æ—Ä–æ—à–æ', '–ø—Ä–æ', '##—Ä–µ–∫', '##–ª–∞–º–∏', '##—Ä–æ–≤–∞–Ω–æ', ',', '–æ–¥–Ω–∞–∫–æ', '—Ç–∞–∫–æ–≥–æ', '—ç', '##—Ñ—Ñ–µ–∫—Ç', '##–∞', '–∫–∞–∫', '–≥–æ–≤–æ—Ä—è—Ç', '–Ω–µ—Ç', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "(18, 29)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example[\"tags\"]), len(tokenized_input[\"input_ids\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 1, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 9, 9, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 17, None]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_input.word_ids())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n"
     ]
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "aligned_labels = [-100 if i is None else example[\"tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        label_ids = [label_list.index(idx) if isinstance(idx, str) else idx for idx in label_ids]\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[2, 3130, 3374, 23324, 871, 314, 1556, 14068, 16902, 1029, 6899, 18, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]]}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_and_align_labels(ner_data['train'][22:23])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/4328 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20cbb5ce6ef843558886eef43af93305"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/481 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ed5b639348f42368731ffece0658566"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = ner_data.map(tokenize_and_align_labels, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "['O',\n 'B-ADR',\n 'B-DI',\n 'B-Drugclass',\n 'B-Drugform',\n 'B-Drugname',\n 'B-Finding',\n 'I-ADR',\n 'I-DI',\n 'I-Drugclass',\n 'I-Drugform',\n 'I-Drugname',\n 'I-Finding']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/47.7M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f088298e3f14bbdbfc32998905afa24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))\n",
    "model.config.id2label = dict(enumerate(label_list))\n",
    "model.config.label2id = {v: k for k, v in model.config.id2label.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='no',\n",
    "    report_to='none',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grayni\\AppData\\Local\\Temp\\ipykernel_18872\\152412463.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94073cb6e0db4ad68704bba51c7b7b68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Python310\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Python310\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'overall_precision': 0.0,\n 'overall_recall': 0.0,\n 'overall_f1': 0.0,\n 'overall_accuracy': 1.0}"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ner_train[4]\n",
    "labels = example['tags']\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels, zero_division=0)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/31 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 2.614814519882202,\n 'eval_precision': 0.0162876784769963,\n 'eval_recall': 0.09378806333739342,\n 'eval_f1': 0.027755249166441384,\n 'eval_accuracy': 0.07054496823804747,\n 'eval_runtime': 4.6115,\n 'eval_samples_per_second': 104.304,\n 'eval_steps_per_second': 6.722}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0020,  0.0191, -0.0035,  ...,  0.0209,  0.0066,  0.0142],\n",
      "        [-0.0308,  0.0264,  0.0095,  ..., -0.0042, -0.0401,  0.0009],\n",
      "        [-0.0140,  0.0128, -0.0170,  ...,  0.0098, -0.0225,  0.0293],\n",
      "        ...,\n",
      "        [ 0.0412,  0.0246, -0.0099,  ...,  0.0154, -0.0049,  0.0187],\n",
      "        [ 0.0347, -0.0499,  0.0164,  ..., -0.0088, -0.0410,  0.0086],\n",
      "        [-0.0183, -0.0075, -0.0209,  ...,  0.0136,  0.0019, -0.0092]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "classifier.bias\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        print(param)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "import logging\n",
    "from transformers.trainer import logger as noisy_logger\n",
    "noisy_logger.setLevel(logging.WARNING)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/2710 : < :, Epoch 0.00/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=2710, training_loss=1.1229413697640394, metrics={'train_runtime': 40.7584, 'train_samples_per_second': 1061.868, 'train_steps_per_second': 66.489, 'total_flos': 40223975493360.0, 'train_loss': 1.1229413697640394, 'epoch': 10.0})"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# —Ä–∞–∑–º–æ—Ä–æ–∑–∫–∞\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='no',\n",
    "    report_to='none',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='5420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/5420 : < :, Epoch 0.00/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=5420, training_loss=0.3395766226567905, metrics={'train_runtime': 205.478, 'train_samples_per_second': 421.262, 'train_steps_per_second': 26.378, 'total_flos': 80410645167600.0, 'train_loss': 0.3395766226567905, 'epoch': 20.0})"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/31 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.3497312366962433,\n 'eval_precision': 0.6329268292682927,\n 'eval_recall': 0.6321559074299634,\n 'eval_f1': 0.6325411334552102,\n 'eval_accuracy': 0.8992811768639251,\n 'eval_runtime': 0.5396,\n 'eval_samples_per_second': 891.375,\n 'eval_steps_per_second': 57.448,\n 'epoch': 20.0}"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ADR': {'precision': 0.39267015706806285,\n  'recall': 0.2830188679245283,\n  'f1': 0.32894736842105265,\n  'number': 265},\n 'DI': {'precision': 0.44623655913978494,\n  'recall': 0.5460526315789473,\n  'f1': 0.49112426035502954,\n  'number': 456},\n 'Drugclass': {'precision': 0.803680981595092,\n  'recall': 0.8136645962732919,\n  'f1': 0.8086419753086419,\n  'number': 161},\n 'Drugform': {'precision': 0.8383458646616542,\n  'recall': 0.8352059925093633,\n  'f1': 0.8367729831144465,\n  'number': 267},\n 'Drugname': {'precision': 0.7833698030634574,\n  'recall': 0.8927680798004988,\n  'f1': 0.8344988344988346,\n  'number': 401},\n 'Finding': {'precision': 0.4,\n  'recall': 0.021739130434782608,\n  'f1': 0.041237113402061855,\n  'number': 92},\n 'overall_precision': 0.6329268292682927,\n 'overall_recall': 0.6321559074299634,\n 'overall_f1': 0.6325411334552102,\n 'overall_accuracy': 0.8992811768639251}"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "                O  B-ADR  B-DI  B-Drugclass  B-Drugform  B-Drugname  \\\nO            9616     19    60            9          22          41   \nB-ADR          93     79    74            7           1           0   \nB-DI          154     17   266            0           8           4   \nB-Drugclass    21      1     4          131           0           4   \nB-Drugform     32      0     2            2         224           7   \nB-Drugname     17      0     7            3           4         367   \nB-Finding      21     23    32            2           4           5   \nI-ADR         110     13    18            1           1           0   \nI-DI          142     13    54            1           0           0   \nI-Drugclass     0      0     0            0           0           0   \nI-Drugform      2      0     0            0           1           0   \nI-Drugname      8      0     0            0           1          29   \nI-Finding      17      5     1            7           0           0   \n\n             B-Finding  I-ADR  I-DI  I-Drugclass  I-Drugform  I-Drugname  \\\nO                    0      5    19            0           0           0   \nB-ADR                3      5     3            0           0           0   \nB-DI                 0      0     7            0           0           0   \nB-Drugclass          0      0     0            0           0           0   \nB-Drugform           0      0     0            0           0           0   \nB-Drugname           0      0     3            0           0           0   \nB-Finding            2      0     3            0           0           0   \nI-ADR                0     38    21            0           0           0   \nI-DI                 0      6    36            0           0           0   \nI-Drugclass          0      0     0            0           0           0   \nI-Drugform           0      0     0            0           0           0   \nI-Drugname           0      0     0            0           0           0   \nI-Finding            0      2     4            0           0           0   \n\n             I-Finding  \nO                    0  \nB-ADR                0  \nB-DI                 0  \nB-Drugclass          0  \nB-Drugform           0  \nB-Drugname           0  \nB-Finding            0  \nI-ADR                0  \nI-DI                 0  \nI-Drugclass          0  \nI-Drugform           0  \nI-Drugname           0  \nI-Finding            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>O</th>\n      <th>B-ADR</th>\n      <th>B-DI</th>\n      <th>B-Drugclass</th>\n      <th>B-Drugform</th>\n      <th>B-Drugname</th>\n      <th>B-Finding</th>\n      <th>I-ADR</th>\n      <th>I-DI</th>\n      <th>I-Drugclass</th>\n      <th>I-Drugform</th>\n      <th>I-Drugname</th>\n      <th>I-Finding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>O</th>\n      <td>9616</td>\n      <td>19</td>\n      <td>60</td>\n      <td>9</td>\n      <td>22</td>\n      <td>41</td>\n      <td>0</td>\n      <td>5</td>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B-ADR</th>\n      <td>93</td>\n      <td>79</td>\n      <td>74</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>5</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B-DI</th>\n      <td>154</td>\n      <td>17</td>\n      <td>266</td>\n      <td>0</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B-Drugclass</th>\n      <td>21</td>\n      <td>1</td>\n      <td>4</td>\n      <td>131</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B-Drugform</th>\n      <td>32</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>224</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B-Drugname</th>\n      <td>17</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>4</td>\n      <td>367</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B-Finding</th>\n      <td>21</td>\n      <td>23</td>\n      <td>32</td>\n      <td>2</td>\n      <td>4</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>I-ADR</th>\n      <td>110</td>\n      <td>13</td>\n      <td>18</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>38</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>I-DI</th>\n      <td>142</td>\n      <td>13</td>\n      <td>54</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>I-Drugclass</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>I-Drugform</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>I-Drugname</th>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>29</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>I-Finding</th>\n      <td>17</td>\n      <td>5</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(sum(true_labels, []), sum(true_predictions, []), labels=label_list),\n",
    "    index=label_list,\n",
    "    columns=label_list\n",
    ")\n",
    "cm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "('ner_bert.bin\\\\tokenizer_config.json',\n 'ner_bert.bin\\\\special_tokens_map.json',\n 'ner_bert.bin\\\\vocab.txt',\n 'ner_bert.bin\\\\added_tokens.json',\n 'ner_bert.bin\\\\tokenizer.json')"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('ner_bert.bin')\n",
    "tokenizer.save_pretrained('ner_bert.bin')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "'–û—Ö–æ—Ç–Ω–æ –ø—Ä–∏–º–µ–Ω—è—é –µ–≥–æ –ø—Ä–∏ –±–æ—Ä—å–±–µ —Å –Ω–∞—Å–º–æ—Ä–∫–æ–º , —á—Ç–æ –≤ –º–æ–µ–º —Å–ª—É—á–∞–µ —è–≤–ª–µ–Ω–∏–µ –æ—á–µ–Ω—å —á–∞—Å—Ç–æ–µ .'"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(ner_train[8]['tokens'])\n",
    "text = ' '.join(ner_test[4]['tokens'])\n",
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 29, 13])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(text, return_tensors='pt')\n",
    "tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(**tokens)\n",
    "pred.logits.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           O         \n",
      "–û               O         \n",
      "##—Ö–æ            O         \n",
      "##—Ç–Ω–æ           O         \n",
      "–ø—Ä–∏             O         \n",
      "##–º–µ–Ω           O         \n",
      "##—è             O         \n",
      "##—é             O         \n",
      "–µ–≥–æ             O         \n",
      "–ø—Ä–∏             O         \n",
      "–±–æ—Ä—å–±–µ          O         \n",
      "—Å               O         \n",
      "–Ω–∞—Å             B-DI      \n",
      "##–º–æ—Ä           B-DI      \n",
      "##–∫–æ–º           B-DI      \n",
      ",               O         \n",
      "—á—Ç–æ             O         \n",
      "–≤               O         \n",
      "–º               O         \n",
      "##–æ–µ            O         \n",
      "##–º             O         \n",
      "—Å–ª—É—á–∞–µ          O         \n",
      "—è               O         \n",
      "##–≤–ª–µ–Ω–∏–µ        O         \n",
      "–æ—á–µ–Ω—å           O         \n",
      "—á–∞—Å—Ç–æ           O         \n",
      "##–µ             O         \n",
      ".               O         \n",
      "[SEP]           O         \n"
     ]
    }
   ],
   "source": [
    "indices = pred.logits.argmax(dim=-1)[0].cpu().numpy()\n",
    "token_text = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])\n",
    "for t, idx in zip(token_text, indices):\n",
    "    print(f'{t:15s} {label_list[idx]:10s}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "pipe = pipeline(model=model, tokenizer=tokenizer, task='ner', aggregation_strategy='average', device=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û—Ö–æ—Ç–Ω–æ –ø—Ä–∏–º–µ–Ω—è—é –µ–≥–æ –ø—Ä–∏ –±–æ—Ä—å–±–µ —Å –Ω–∞—Å–º–æ—Ä–∫–æ–º , —á—Ç–æ –≤ –º–æ–µ–º —Å–ª—É—á–∞–µ —è–≤–ª–µ–Ω–∏–µ –æ—á–µ–Ω—å —á–∞—Å—Ç–æ–µ .\n",
      "[{'entity_group': 'DI', 'score': 0.7875536, 'word': '–Ω–∞—Å–º–æ—Ä–∫–æ–º', 'start': 33, 'end': 42}]\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(pipe(text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}