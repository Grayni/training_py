{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from telegram.ext  import Updater, CommandHandler, MessageHandler, Filters\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import mmap\n",
    "import re\n",
    "\n",
    "def get_num_lines(file_path):\n",
    "    fp = open(file_path, \"r+\")\n",
    "    buf = mmap.mmap(fp.fileno(), 0)\n",
    "    lines = 0\n",
    "    while buf.readline():\n",
    "        lines += 1\n",
    "    return lines"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "otv_path = \"data/shop/Otvety.txt\"\n",
    "N = get_num_lines(otv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Преобразование файла аопросов-ответов в строчный вид\n",
    "if not os.path.isfile('data/shop/prepared_answers.txt'):\n",
    "\n",
    "    question = None\n",
    "    written = False\n",
    "\n",
    "    with open('data/shop/prepared_answers.txt', \"w\", encoding='utf-8') as fout:\n",
    "        with open(otv_path, \"r\", encoding='utf-8') as fin:\n",
    "            for line in tqdm(fin):\n",
    "                if line.startswith(\"---\"):\n",
    "                    written = False\n",
    "                    continue\n",
    "                if not written and question is not None:\n",
    "                    fout.write(question.replace(\"\\t\", \" \").strip() + \"---\" + line.replace(\"\\t\", \" \"))\n",
    "                    written = True\n",
    "                    question = None\n",
    "                    continue\n",
    "                if not written:\n",
    "                    question = line.strip()\n",
    "                    continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Препроцессинг текста\n",
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Функция для очистки текста из статьи https://habr.com/ru/articles/738176/ адаптированная под русский язык\n",
    "def clean_text(input_text):\n",
    "\n",
    "    # HTML-теги: первый шаг - удалить из входного текста все HTML-теги\n",
    "    clean_text = re.sub('<[^<]+?>', '', input_text)\n",
    "\n",
    "    # URL и ссылки: далее - удаляем из текста все URL и ссылки\n",
    "    clean_text = re.sub(r'http\\S+', '', clean_text)\n",
    "\n",
    "    #Эмоджи и эмотиконы: используем собственную функцию для преобразования эмоджи в текст\n",
    "    #Важно понимать эмоциональную окраску обрабатываемого текста\n",
    "    clean_text = emojis_words(clean_text)\n",
    "\n",
    "    # Приводим все входные данные к нижнему регистру\n",
    "    clean_text = clean_text.lower()\n",
    "\n",
    "    # Убираем все пробелы\n",
    "    # Так как все данные теперь представлены словами - удалим пробелы\n",
    "    clean_text = re.sub('\\s+', ' ', clean_text)\n",
    "\n",
    "    #Убираем специальные символы: избавляемся от всего, что не является \"словами\"\n",
    "    clean_text = re.sub('[^а-яА-ЯёЁ0-9\\s]', '', clean_text) #\n",
    "\n",
    "    # Записываем числа прописью: 100 превращается в \"сто\" (для компьютера)# не работает\n",
    "    temp = inflect.engine()\n",
    "    words = []\n",
    "    for word in clean_text.split():\n",
    "        if word.isdigit():\n",
    "            words.append(num2words(int(word), lang='ru'))\n",
    "        else:\n",
    "            words.append(word)\n",
    "    clean_text = ' '.join(words)\n",
    "\n",
    "        # Стоп-слова: удаление стоп-слов - это стандартная практика очистки текстов\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    tokens = word_tokenize(clean_text)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    clean_text = ' '.join(tokens)\n",
    "\n",
    "    # Знаки препинания: далее - удаляем из текста все знаки препинания\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', clean_text)\n",
    "\n",
    "    # И наконец - возвращаем очищенный текст\n",
    "    return clean_text\n",
    "\n",
    "# Функция для преобразования эмоджи в слова\n",
    "def emojis_words(text):\n",
    "\n",
    "    # Модуль emoji: преобразование эмоджи в их словесные описания\n",
    "    clean_text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "\n",
    "    # Редактирование текста путём замены \":\" и\" _\", а так же - путём добавления пробела между отдельными словами\n",
    "    clean_text = clean_text.replace(\":\", \"\").replace(\"_\", \" \")\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "def preproc_text(text):\n",
    "    res = str(text).strip()\n",
    "    res = re.sub(r\"\\s+\", \" \", res)\n",
    "    return res\n",
    "\n",
    "def build_data(data_q, data_ans):\n",
    "    data = []\n",
    "    for idx, texts in enumerate(data_q):\n",
    "        question = preproc_text(texts)\n",
    "        answer = preproc_text(data_ans.iloc[idx])\n",
    "        res = '\\nx:' + question + '\\ny:' + answer\n",
    "        data.append(res)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Обработка текста\n",
    "\n",
    "sentences = []\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "exclude = {}\n",
    "c = 0\n",
    "\n",
    "file_path_from = 'data/shop/prepared_answers.txt'\n",
    "file_path_to = 'data/shop/Otvety2.txt'\n",
    "\n",
    "if not os.path.isfile(file_path_to):\n",
    "\n",
    "    N = get_num_lines(file_path_from)\n",
    "    with open(file_path_to, mode = 'w', encoding='utf-8') as fileto:\n",
    "        with open(file_path_from, encoding='utf-8') as filefrom:\n",
    "            for k in tqdm(range(N)):\n",
    "                line = filefrom.readline()\n",
    "                if line == '': break\n",
    "                spls = preprocess_txt(line)\n",
    "                sentences.append(spls)\n",
    "                c += 1\n",
    "                if c > 50_000:\n",
    "                    break\n",
    "                fileto.write(' '.join(spls)+'\\n')\n",
    "    filefrom.close()\n",
    "    fileto.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/50000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d830a7613cf947bba5eb04288d61567a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузить результат\n",
    "\n",
    "sentences = []\n",
    "\n",
    "file_path_from = 'data/shop/Otvety2.txt'\n",
    "if os.path.isfile(file_path_from):\n",
    "    N = get_num_lines(file_path_from)\n",
    "    with open(file_path_to, mode = 'r', encoding='utf-8') as filefrom:\n",
    "        for k in tqdm(range(N)):\n",
    "            line = filefrom.readline()\n",
    "            if line == '': break\n",
    "            sentences.append(line.split())\n",
    "    filefrom.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "['%',\n '(',\n '(+)',\n '(205—239),',\n '(28—75)',\n '(299—325)',\n '(439—472)',\n '(452—498)',\n '(534—560)',\n '(5строк)']"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = []\n",
    "_ = [vec.extend(x)  for x in sentences[:100]]\n",
    "vec = list(set(vec))\n",
    "vec.sort()\n",
    "vec[20:30]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "[['---вопрос',\n  'тдв))',\n  'отдыхаем))',\n  'лично',\n  'советовать',\n  'завести?))',\n  '.'],\n ['парень',\n  'относиться',\n  'цветной',\n  'линзам?',\n  'девушка',\n  'зелёный',\n  'глаза,',\n  'голубые...))',\n  '.---менить',\n  'вобщий',\n  'прикалывать',\n  'тема',\n  ':).'],\n ['делать,',\n  'найти',\n  '2',\n  'миллион',\n  'рублей?',\n  '.---ести',\n  '\"счастие',\n  '\"',\n  'свалилось,',\n  'хороший',\n  'пойти',\n  'милиция',\n  'заявить',\n  'находке.',\n  'деньга',\n  'терют,',\n  'самый',\n  'интересный',\n  'неприменный',\n  'искать',\n  'поверьте',\n  'найдут,',\n  'видеть',\n  'подобный',\n  'жизни.',\n  'нарваться',\n  'бабушка',\n  'конечно,',\n  'помочий',\n  'внук',\n  'покупка',\n  'квартиры,',\n  'бандитов,',\n  'разговаривать',\n  'иначе',\n  'бабушка',\n  'милицией.',\n  'выбор',\n  'вами,',\n  'шанс,',\n  'подарок',\n  'выше',\n  'котрый',\n  'никто',\n  'спросит,',\n  'хороший',\n  'отдать',\n  'хотяб',\n  '500',\n  'благотворительность.',\n  'дабы',\n  'спугнуть',\n  'удачу!.'],\n ['эбу',\n  'двенашка',\n  'называться',\n  'итэлма',\n  'эбу?',\n  '.---эб',\n  '—',\n  'электронный',\n  'блок',\n  'управление',\n  'двигатель',\n  'автомобиля,',\n  'название',\n  '—',\n  'контроллер.',\n  'принимать',\n  'информация',\n  'датчиков,',\n  'обрабатывать',\n  'особый',\n  'алгоритм',\n  'и,',\n  'отталкиваться',\n  'получить',\n  'данных,',\n  'отдавать',\n  'команда',\n  'исполнительный',\n  'устройство',\n  'системы..'],\n ['академия',\n  'вампиров.',\n  'даный',\n  'момент',\n  'часть',\n  'книга',\n  'академия',\n  'вампиров?',\n  '.---4.',\n  'охотник',\n  'жертвы,',\n  'ледяной',\n  'укус,',\n  'поцелуй',\n  'тьмы,',\n  'кровный',\n  'клятва.'],\n ['защититься',\n  'энергетический',\n  'вампир',\n  '.---защита',\n  'мыслью.',\n  '<br>каждый',\n  'должный',\n  'отношение',\n  'вампир',\n  'взять',\n  'правило:',\n  '\"ич',\n  'страшный',\n  'серый',\n  'волк\",',\n  'знать,',\n  'конкретный',\n  '\"серый',\n  'волк\"',\n  '-',\n  'вампир',\n  'существует,',\n  'воспринимать',\n  'следовать',\n  'хищника,',\n  'добрый',\n  'домашний',\n  'собачку.',\n  '\"собачка\"',\n  'быстро',\n  'почувствует,',\n  '\"того',\n  'поле',\n  'ягода\"',\n  'быстро',\n  'отстать',\n  'сама.',\n  '<br>\"витание',\n  'облаках\".',\n  '<br>тожий',\n  'хороший',\n  'способ.',\n  'мысленно',\n  'представить',\n  'находиться',\n  'окружение',\n  'приятный',\n  'ощущение',\n  'белый',\n  'облако',\n  'сине-голубой',\n  'неба.',\n  'эффективно.',\n  '<br>\"подкормка',\n  'негативом\".',\n  '<br>вампир',\n  'кушать?',\n  'дать',\n  'ему.',\n  'собрать',\n  'плохой',\n  'мысли,',\n  'эмоции,',\n  'отрицательное,',\n  'какой-то',\n  'образ',\n  'закрасться',\n  'организм.',\n  '\"тяжесть\"',\n  'отдать',\n  'вампир',\n  '-',\n  'пусть',\n  'подавится.',\n  '<br>зеркало',\n  '<br>переть',\n  'встреча',\n  'общение',\n  'неприятный',\n  'мысленно',\n  'представить,',\n  'зеркальный',\n  'стена,',\n  'обратить',\n  'отражать',\n  'поверхность',\n  'человеку.',\n  '<br>\"дикобраз\"',\n  '<br>этота',\n  'способ',\n  'выглядеть',\n  'следующий',\n  'образом:',\n  'человек,',\n  'почувствовать',\n  'опасность,',\n  'мысленно',\n  'покрывать',\n  'свой',\n  'биополе',\n  'игла',\n  'шипами.',\n  'энергетический',\n  'вампир,',\n  'попробовать',\n  'высосать',\n  'биоэнергию,',\n  'ощущать',\n  'боль',\n  'прикосновение',\n  'биополей.',\n  '<br>замыкание',\n  'контур',\n  'биополя.',\n  '<br>',\n  '<br>существовать',\n  'способа.',\n  'выбирать',\n  'удобный',\n  'ему.',\n  'способ',\n  'заключаться',\n  'скрещивание',\n  'нога',\n  'рука',\n  'общение',\n  'человеком,',\n  'ждать',\n  'неприятностей.',\n  'способ',\n  'заключаться',\n  'следующем:',\n  'большой',\n  'указательный',\n  'палец',\n  'рука',\n  'соединить',\n  'больший',\n  'указательный',\n  'палец',\n  'руки,',\n  'образовать',\n  'кольцо,',\n  'остальной',\n  'палец',\n  'рука',\n  'наложить',\n  'друг',\n  'друга.',\n  'способ',\n  'эффективны,',\n  'благодаря',\n  'замыкаться',\n  'контур',\n  'биополя,',\n  'оставлять',\n  'пробоин,',\n  'энергетический',\n  'вампир',\n  'пробиться',\n  'защита',\n  'вытянуть',\n  'биоэнергию.',\n  '<br>',\n  '<br>все',\n  'приём',\n  'делать',\n  'незаметно,',\n  'демонстрировать',\n  'свой',\n  'действие',\n  'привлекать',\n  'внимание',\n  'окружающих..'],\n ['выращивать',\n  'магнолия',\n  'открытый',\n  'грунт',\n  'средний',\n  'полоса',\n  'россия',\n  '?',\n  'вид',\n  'сорт',\n  '?',\n  'зимовать',\n  'укрытие',\n  'укрытие',\n  '?',\n  'цвести',\n  '?',\n  'магнолия',\n  '?',\n  'каков',\n  'размер',\n  'дерево',\n  '?',\n  'особенность',\n  'выращивание',\n  '?',\n  'пожалуйста,',\n  'указывать',\n  'ответ',\n  'регион',\n  'и,',\n  'можно,',\n  'прикреплять',\n  'фото..---й',\n  'выращиваю.',\n  'хабаровск.',\n  'дв.',\n  '<br>ть',\n  'кратце.',\n  'прочитать',\n  'сайт',\n  'метод',\n  'выращивание',\n  'магнолия',\n  'средний',\n  'полосе:',\n  'купить',\n  'черенок',\n  'растения,',\n  '3-4',\n  'выращиваться',\n  'кадочный',\n  'растение,',\n  'роза.',\n  'лето',\n  'улице,',\n  'зима',\n  '-',\n  'погреб',\n  'прохладный',\n  'помещение,',\n  'тип',\n  'холодильника.',\n  'весны.',\n  'весна',\n  '-',\n  'сад.',\n  'так,',\n  'нарастить',\n  'мощный',\n  'корневой',\n  'систему.',\n  '3-4',\n  'высаживать',\n  'грунт,',\n  'зима',\n  'укрывать,',\n  'возможности.',\n  '<br>моя',\n  '1',\n  'год,',\n  'ращу.',\n  '<br>сорт',\n  ':',\n  'магнолия',\n  'susan.<br>.'],\n ['отформатировать',\n  'диск',\n  'c',\n  'дос',\n  'формат',\n  'ntfs',\n  'команда',\n  'fdisk',\n  '-',\n  'жёсткий',\n  'диск',\n  'найти',\n  '.---скачать',\n  'программа',\n  'акронис',\n  'диск',\n  'директор,',\n  'загрузочный',\n  'версию.'],\n ['относиться',\n  'парикмахерам,',\n  'работать',\n  'дому?',\n  'помешать',\n  'например',\n  'присутствие',\n  'дом',\n  'ребенка?',\n  'мужа.',\n  'нормально',\n  'мыть',\n  'голова',\n  'ванная',\n  '\"раком\"?.---ести',\n  'профессионал',\n  'нет.главное',\n  'остаться',\n  'довольный',\n  'результатом.ситуация',\n  'разный',\n  'бывают.мочь',\n  'мамочка',\n  'декрете.мочь',\n  'выгодный',\n  'работать',\n  'себя,без',\n  'аренда',\n  'вкусностей.д',\n  'правило',\n  'цена',\n  'услуга',\n  'ниже.',\n  'общение',\n  'свободней.можный',\n  'получить',\n  'хороший',\n  'друг',\n  'собеседника..'],\n ['кошка', 'олег', 'видели)?', '.---♦•давно', 'олег', 'стать', 'котом•♦.']]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Обучим модель FastText\n",
    "\n",
    "file_path_from = 'models/ft_model'\n",
    "if not os.path.isfile(file_path_from):\n",
    "\n",
    "    sentences = [i for i in tqdm(sentences) if len(i) > 2]\n",
    "    modelFT = FastText(sentences=sentences, vector_size=100, min_count=1, window=5)\n",
    "    modelFT.save(\"models/ft_model\")\n",
    "    ft_index = annoy.AnnoyIndex(100 ,'angular')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Загрузить модель\n",
    "\n",
    "modelFT = FastText.load(\"models/ft_model\")\n",
    "ft_index = annoy.AnnoyIndex(100 ,'angular')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "['этим',\n 'теперь',\n 'м',\n 'те',\n 'вся',\n 'однако',\n 'дальше',\n 'шестнадцать',\n 'теми',\n 'обычно',\n 'особенно',\n 'непрерывно',\n 'какой',\n 'также',\n 'процентов',\n 'году',\n 'вон',\n 'но',\n 'наши',\n 'чаще']"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(get_stop_words(\"ru\")))[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d65af51d1e4a40e7aad4b93d002c5f8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создаем Индексы для вопросов-ответов\n",
    "\n",
    "file_path_from = 'speakers/speaker.ann'\n",
    "if not os.path.isfile(file_path_from):\n",
    "    morpher = MorphAnalyzer()\n",
    "    sw = set(get_stop_words(\"ru\"))\n",
    "    exclude = set(string.punctuation)\n",
    "    modelFT = FastText.load(\"models/ft_model\")\n",
    "    ft_index = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "    index_map = {}\n",
    "    counter = 0\n",
    "    with open(\"data/shop/Otvety2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f):\n",
    "            n_ft = 0\n",
    "            spls = line.split(\"---\")\n",
    "            index_map[counter] = spls[1]\n",
    "            question = preprocess_txt(spls[0])\n",
    "            vector_ft = np.zeros(100)\n",
    "            for word in question:\n",
    "                if word in modelFT.wv:\n",
    "                    vector_ft += modelFT.wv[word]\n",
    "                    n_ft += 1\n",
    "            if n_ft > 0:\n",
    "                vector_ft = vector_ft / n_ft\n",
    "            ft_index.add_item(counter, vector_ft)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            if counter > 50_000:\n",
    "                break\n",
    "\n",
    "    ft_index.build(10)\n",
    "    ft_index.save('speakers/speaker.ann')\n",
    "\n",
    "    with open(\"speakers/index_speaker.pkl\", \"wb\") as f:\n",
    "        pickle.dump(index_map, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "#  Загрузим индексы\n",
    "ft_index = annoy.AnnoyIndex(100, 'angular')\n",
    "ft_index.load('speakers/speaker.ann')\n",
    "index_map = pd.read_pickle(\"speakers/index_speaker.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "array([30, 26, 15, 20, 29, 22, 92, 11,  1, 95, 82, 88, 34, 37, 94,  2, 79,\n       42, 68, 99, 81, 83, 13,  6, 38,  8, 77, 78, 16, 40, 39, 73, 19, 47,\n       17, 89,  5, 51, 58, 43, 55, 35, 59, 14, 90, 48,  4, 64, 63, 52,  3,\n       49, 86, 45, 84, 87, 70, 60, 66, 44, 74, 56, 33, 61, 12, 75, 31, 41,\n       97, 28, 32, 27, 76, 36, 23, 80, 24, 85, 18, 98, 53, 25, 62, 67, 69,\n       50, 10, 72, 57, 93, 91,  0, 46,  7, 54,  9, 21, 96, 65, 71])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "([28111, 21302, 2162, 40334, 4320],\n [1.3629968166351318,\n  1.365588665008545,\n  1.3672868013381958,\n  1.3673839569091797,\n  1.3677575588226318])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Пример получения индексов\n",
    "a = ft_index.get_nns_by_vector(np.random.permutation(100), 5, include_distances=True)\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "['главное нравилось, рука брюках!).\\n',\n 'сказать себе. лично любить поцелую. раздражать неприятно становится. фильм вижу, барышня нравиться вид поцелуев. наверное, сугубо индивидуально. возбуждать (эрогенный зона), кто-то раздражает, пример меня. наверное я, мало, основное большинство нравиться нежный прикосновение шее..\\n',\n 'кто любит?))))))).\\n',\n ' по-моему нет!!!! по-настоящему любить душой! ухо либо часть тела. настоящий любовь-это соприкосновение душ... неужели комплимент реагировать положительно??? задумайся=))).\\n',\n 'как никто? я?))).\\n']"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index_map[x] for x in a[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/35548 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "460062a34b574b87850e970156827282"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  title                                       descrirption  \\\n0     Юбка детская ORBY  Новая, не носили ни разу. В реале красивей чем...   \n1             Ботильоны  Новые,привезены из Чехии ,указан размер 40,но ...   \n2                 Брюки  Размер 40-42. Брюки почти новые - не знаю как ...   \n3  Продам детские шапки  Продам шапки,кажда 200р.Розовая и белая проданны.   \n4                Блузка  Темно-синяя, 42 размер,состояние отличное,как ...   \n\n                 product_id  category_id subcategory_id  \\\n0  58e3cfe6132ca50e053f5f82         22.0           2211   \n1  5667531b2b7f8d127d838c34          9.0            902   \n2  59534826aaab284cba337e06          9.0            906   \n3  57de544096ad842e26de8027         22.0           2217   \n4  5ad4d2626c86cb168d212022          9.0            907   \n\n                                          properties  \\\n0        {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n1  {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n2  {'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...   \n3  {'detskie_pol': 'Девочкам', 'detskaya_odezhda_...   \n4  {'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...   \n\n                                         image_links  \\\n0  http://cache3.youla.io/files/images/360_360/58...   \n1  http://cache3.youla.io/files/images/360_360/5b...   \n2  http://cache3.youla.io/files/images/360_360/59...   \n3  http://cache3.youla.io/files/images/360_360/57...   \n4  http://cache3.youla.io/files/images/360_360/5a...   \n\n                                                text  \n0  [юбка, детский, orby, новый, носить, реал, кра...  \n1  [ботильон, новыепривезти, чехия, указать, разм...  \n2  [брюки, размер, 4042, брюки, новый, знать, мер...  \n3  [продать, детский, шапка, продать, шапкикажда,...  \n4  [блузка, темносиний, 42, размерсостояние, отли...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>descrirption</th>\n      <th>product_id</th>\n      <th>category_id</th>\n      <th>subcategory_id</th>\n      <th>properties</th>\n      <th>image_links</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Юбка детская ORBY</td>\n      <td>Новая, не носили ни разу. В реале красивей чем...</td>\n      <td>58e3cfe6132ca50e053f5f82</td>\n      <td>22.0</td>\n      <td>2211</td>\n      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n      <td>[юбка, детский, orby, новый, носить, реал, кра...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ботильоны</td>\n      <td>Новые,привезены из Чехии ,указан размер 40,но ...</td>\n      <td>5667531b2b7f8d127d838c34</td>\n      <td>9.0</td>\n      <td>902</td>\n      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n      <td>[ботильон, новыепривезти, чехия, указать, разм...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Брюки</td>\n      <td>Размер 40-42. Брюки почти новые - не знаю как ...</td>\n      <td>59534826aaab284cba337e06</td>\n      <td>9.0</td>\n      <td>906</td>\n      <td>{'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...</td>\n      <td>http://cache3.youla.io/files/images/360_360/59...</td>\n      <td>[брюки, размер, 4042, брюки, новый, знать, мер...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Продам детские шапки</td>\n      <td>Продам шапки,кажда 200р.Розовая и белая проданны.</td>\n      <td>57de544096ad842e26de8027</td>\n      <td>22.0</td>\n      <td>2217</td>\n      <td>{'detskie_pol': 'Девочкам', 'detskaya_odezhda_...</td>\n      <td>http://cache3.youla.io/files/images/360_360/57...</td>\n      <td>[продать, детский, шапка, продать, шапкикажда,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Блузка</td>\n      <td>Темно-синяя, 42 размер,состояние отличное,как ...</td>\n      <td>5ad4d2626c86cb168d212022</td>\n      <td>9.0</td>\n      <td>907</td>\n      <td>{'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...</td>\n      <td>http://cache3.youla.io/files/images/360_360/5a...</td>\n      <td>[блузка, темносиний, 42, размерсостояние, отли...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим модель продуктовых данных\n",
    "\n",
    "shop_data = pd.read_csv(\"data/shop/ProductsDataset.csv\")\n",
    "#shop_data = shop_data.iloc[:5000, :]\n",
    "\n",
    "shop_data['text'] = shop_data['title'] + \" \" + shop_data[\"descrirption\"]\n",
    "shop_data['text'] = shop_data['text'].progress_apply(lambda x: preprocess_txt(str(x)))\n",
    "shop_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Подготовка для создания модели для определения домена данных\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/25493 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3eb0ab3ec564364acaf19a8bb297ff4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/35548 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c22db8fc5cf47998b346e4b22ae57ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idxs = set(np.random.randint(0, len(index_map), len(shop_data)))\n",
    "# Вопрос-ответный домен\n",
    "negative_texts = [\" \".join(preprocess_txt(index_map[i])) for i in tqdm(idxs)]\n",
    "# Продуктовый домен\n",
    "positive_texts = [\" \".join(val) for val in tqdm(shop_data['text'].values)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# ВО = 0, Прод = 1\n",
    "\n",
    "dataset = negative_texts + positive_texts\n",
    "labels = np.zeros(len(dataset))\n",
    "labels[len(negative_texts):] = np.ones(len(positive_texts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2,\n",
    "                                                    stratify=labels, random_state=13)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Модель\n",
    "\n",
    "x_train_vec = vectorizer.fit_transform(X_train)\n",
    "x_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression().fit(x_train_vec, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9780489802604636"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Качество\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true=y_test, y_pred=lr.predict(x_test_vec))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer().fit(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "10.771305851642047"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tfidf_vect.idf_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "idfs = {v[0]: v[1] for v in zip(tfidf_vect.vocabulary_, tfidf_vect.idf_)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "149748"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idfs.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "['мокасин', 'новый', 'кожа', '35', 'рр']"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(idfs.keys())[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "[9.023572870569504,\n 7.017038099697756,\n 10.409867231689395,\n 11.10301441224934,\n 11.10301441224934]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(idfs.values())[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Создаем Индексы для продуктовых данных\n",
    "\n",
    "file_path_from = 'speakers/shop.ann'\n",
    "if not os.path.isfile(file_path_from):\n",
    "\n",
    "\n",
    "    ft_index_shop = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "    midf = np.mean(tfidf_vect.idf_)\n",
    "\n",
    "    index_map_shop = {}\n",
    "    counter = 0\n",
    "\n",
    "    for i in tqdm(range(len(shop_data))):\n",
    "        n_ft = 0\n",
    "        index_map_shop[counter] = (shop_data.loc[i, \"title\"], shop_data.loc[i, \"image_links\"])\n",
    "        vector_ft = np.zeros(100)\n",
    "        for word in shop_data.loc[i, \"text\"]:\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "                n_ft += idfs.get(word, midf)\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        ft_index_shop.add_item(counter, vector_ft)\n",
    "        counter += 1\n",
    "\n",
    "    ft_index_shop.build(10)\n",
    "    ft_index_shop.save('speakers/shop.ann')\n",
    "\n",
    "    file_path_from = 'speakers/index_shop.pkl'\n",
    "    if not os.path.isfile(file_path_from):\n",
    "\n",
    "        with open(\"speakers/index_shop.pkl\", \"wb\") as f:\n",
    "            pickle.dump(index_map_shop, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Загрузим индексы\n",
    "\n",
    "midf = np.mean(tfidf_vect.idf_)\n",
    "\n",
    "ft_index_shop = annoy.AnnoyIndex(100, 'angular')\n",
    "ft_index_shop.load('speakers/shop.ann')\n",
    "\n",
    "index_map_shop = pd.read_pickle(\"speakers/index_shop.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Основная функция преобразования текста в вектор х100\n",
    "\n",
    "def embed_txt(txt, idfs, midf):\n",
    "    n_ft = 0\n",
    "    vector_ft = np.zeros(100)\n",
    "    for word in txt:\n",
    "        if word in modelFT.wv:\n",
    "            vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "            n_ft += idfs.get(word, midf)\n",
    "    return vector_ft / n_ft"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "([5611, 24871, 5046, 4373, 7546],\n [1.372674584388733,\n  1.3737328052520752,\n  1.3952107429504395,\n  1.3981150388717651,\n  1.3984076976776123])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример получения индекса\n",
    "\n",
    "ft_index_shop.get_nns_by_vector(np.ones(100)*20, 5, include_distances=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# заменить на свой токен\n",
    "updater = Updater(\"6443609460:AAEeYjOgR2yMTGIvqB3qDBLpNAXzIL5xnf8\", use_context=True) # Токен API к Telegram\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "def startCommand(update, context):\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text='Привет, давай пообщаемся?')\n",
    "\n",
    "def textMessage(update, context):\n",
    "\n",
    "    input_txt = preprocess_txt(update.message.text)\n",
    "    vect = vectorizer.transform([\" \".join(input_txt)])\n",
    "    prediction = lr.predict(vect)\n",
    "\n",
    "    # ПРОД\n",
    "    if prediction[0] == 1:\n",
    "        vect_ft = embed_txt(input_txt, idfs, midf)\n",
    "        ft_index_shop_val = ft_index_shop.get_nns_by_vector(vect_ft, 5)\n",
    "        for item in ft_index_shop_val:\n",
    "            title, image = index_map_shop[item]\n",
    "            context.bot.send_message(chat_id=update.message.chat_id, text=\"title: {} image: {}\".format(title, image))\n",
    "        return\n",
    "\n",
    "    # QA\n",
    "    vect_ft = embed_txt(input_txt, {}, 1)\n",
    "    ft_index_val, distances = ft_index.get_nns_by_vector(vect_ft, 1, include_distances=True)\n",
    "\n",
    "    #\n",
    "    if distances[0] > 100.5:\n",
    "        print(distances[0])\n",
    "        context.bot.send_message(chat_id=update.message.chat_id, text=\"Моя твоя не понимать\")\n",
    "        return\n",
    "\n",
    "    # Вопрос-Ответ\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=index_map[ft_index_val[0]])\n",
    "\n",
    "start_command_handler = CommandHandler('start', startCommand)\n",
    "text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "dispatcher.add_handler(start_command_handler)\n",
    "dispatcher.add_handler(text_message_handler)\n",
    "updater.start_polling(clean=True)\n",
    "updater.idle()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python-telegram-bot v 13.3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}