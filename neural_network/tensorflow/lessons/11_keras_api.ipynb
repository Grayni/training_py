{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10, mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 1. Set seed\n",
    "tf.random.set_seed(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 2. Layers\n",
    "input = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(64, 3, activation='relu')(input) # get previous layer â†‘\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(10, activation='softmax')(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1568)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               401664    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424,490\n",
      "Trainable params: 424,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs=input, outputs=output)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 36s 56ms/step - loss: 1.6014 - accuracy: 0.4175 - val_loss: 1.3303 - val_accuracy: 0.5287\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 31s 49ms/step - loss: 1.2753 - accuracy: 0.5450 - val_loss: 1.1192 - val_accuracy: 0.6134\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 28s 45ms/step - loss: 1.1354 - accuracy: 0.5983 - val_loss: 1.1037 - val_accuracy: 0.6158\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 1.0395 - accuracy: 0.6338 - val_loss: 0.9837 - val_accuracy: 0.6599\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.9699 - accuracy: 0.6593 - val_loss: 0.9615 - val_accuracy: 0.6750\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.9226 - accuracy: 0.6754 - val_loss: 0.9035 - val_accuracy: 0.6908\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 0.8743 - accuracy: 0.6931 - val_loss: 0.8886 - val_accuracy: 0.6945\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 27s 44ms/step - loss: 0.8404 - accuracy: 0.7041 - val_loss: 0.9320 - val_accuracy: 0.6848\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 0.8035 - accuracy: 0.7192 - val_loss: 0.8667 - val_accuracy: 0.7049\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 29s 46ms/step - loss: 0.7637 - accuracy: 0.7314 - val_loss: 0.8457 - val_accuracy: 0.7094\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 27s 44ms/step - loss: 0.7288 - accuracy: 0.7426 - val_loss: 0.8625 - val_accuracy: 0.7119\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.7060 - accuracy: 0.7497 - val_loss: 0.8439 - val_accuracy: 0.7157\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.6805 - accuracy: 0.7603 - val_loss: 0.8664 - val_accuracy: 0.7071\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 29s 46ms/step - loss: 0.6536 - accuracy: 0.7678 - val_loss: 0.8863 - val_accuracy: 0.7056\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 28s 45ms/step - loss: 0.6297 - accuracy: 0.7761 - val_loss: 0.8741 - val_accuracy: 0.7106\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 28s 45ms/step - loss: 0.6115 - accuracy: 0.7785 - val_loss: 0.8503 - val_accuracy: 0.7174\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 27s 44ms/step - loss: 0.5908 - accuracy: 0.7889 - val_loss: 0.8747 - val_accuracy: 0.7199\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.5626 - accuracy: 0.7975 - val_loss: 0.8864 - val_accuracy: 0.7145\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.5478 - accuracy: 0.8030 - val_loss: 0.8905 - val_accuracy: 0.7141\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.5262 - accuracy: 0.8098 - val_loss: 0.8879 - val_accuracy: 0.7192\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20bf975fb80>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=20, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.8948 - accuracy: 0.7140\n",
      "[0.8947611451148987, 0.7139999866485596]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# On level tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class TfConv2D(tf.Module):\n",
    "    def __init__(self, kernel=(3, 3), channels=1, strides=(2, 2), padding='SAME', activate='relu'):\n",
    "        super().__init__()\n",
    "        self.kernel = kernel\n",
    "        self.channels = channels\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.activate = activate\n",
    "        self.fl_init = False\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not self.fl_init:\n",
    "            # [kernel_x, kernel_y, input_channels, output_channels]\n",
    "            self.w = tf.random.truncated_normal((*self.kernel, x.shape[-1], self.channels), stddev=0.1, dtype=tf.double)\n",
    "            self.b = tf.zeros([self.channels], dtype=tf.double)\n",
    "\n",
    "            self.w = tf.Variable(self.w)\n",
    "            self.b = tf.Variable(self.b)\n",
    "\n",
    "            self.fl_init = True\n",
    "\n",
    "        y = tf.nn.conv2d(x, self.w, strides=(1, *self.strides, 1), padding=self.padding) + self.b\n",
    "\n",
    "        if self.activate == 'relu':\n",
    "            return tf.nn.relu(y)\n",
    "        elif self.activate == 'softmax':\n",
    "            return tf.nn.softmax(y)\n",
    "\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 16, 32)\n"
     ]
    }
   ],
   "source": [
    "layer1 = TfConv2D((3, 3), 32)\n",
    "y = layer1(tf.expand_dims(x_test[0], axis=0))\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8, 8, 32)\n"
     ]
    }
   ],
   "source": [
    "y = tf.nn.max_pool2d(y, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1), padding='SAME')\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "enc_input = layers.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation='relu')(enc_input)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "enc_output = layers.Dense(8, activation='linear')(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "encoder = keras.Model(enc_input, enc_output, name='encoder')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train / 255\n",
    "y_train = y_train / 255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "dec_input = layers.Input(shape=(8,), name='encoder_img')\n",
    "x = layers.Dense(7 * 7 * 8, activation='relu')(dec_input)\n",
    "x = keras.layers.Reshape((7, 7, 8))(x)\n",
    "x = layers.Conv2DTranspose(64, 5, strides=(2, 2), activation='relu', padding='same')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(32, 5, strides=(2, 2), activation='linear', padding='same')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "dec_output = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "decoder = keras.Model(dec_input, dec_output, name='decoder')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
    "x = encoder(autoencoder_input)\n",
    "autoencoder_output = decoder(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "autoencoder = keras.Model(autoencoder_input, autoencoder_output, name='autoencoder')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 73s 38ms/step - loss: 0.0306\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20b89b36bc0>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(x_train, x_train, batch_size=32, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    }
   ],
   "source": [
    "h = encoder.predict(tf.expand_dims(x_test[0], axis=0))\n",
    "img = decoder.predict(h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(x_test[0], cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}