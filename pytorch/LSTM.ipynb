{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   tweet  label\n6      christmas eve? what about christmas adam? this...      1\n15     @user #allahsoil like all religions, islam can...      1\n29     here's a ?for the day the government and state...      1\n30     scapelliti:  progresverebel: ha! good riddance...      1\n34     @user racist attack on three muslim women in #...      1\n...                                                  ...    ...\n22291  #sikh #temple vandalised in in #calgary, #wso ...      1\n22292  not even trumpâs transition team wants to de...      1\n22310  @user my #santaproject is to not shop at @user...      1\n22356                                    dull british .       1\n22370  black professor makes assumptions about an ent...      1\n\n[1558 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>christmas eve? what about christmas adam? this...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>@user #allahsoil like all religions, islam can...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>here's a ?for the day the government and state...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>scapelliti:  progresverebel: ha! good riddance...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>@user racist attack on three muslim women in #...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22291</th>\n      <td>#sikh #temple vandalised in in #calgary, #wso ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22292</th>\n      <td>not even trumpâs transition team wants to de...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22310</th>\n      <td>@user my #santaproject is to not shop at @user...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22356</th>\n      <td>dull british .</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22370</th>\n      <td>black professor makes assumptions about an ent...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1558 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/twitter/train.csv')\n",
    "\n",
    "X_data = df['tweet'].values\n",
    "y_data = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "df_train = pd.DataFrame({'tweet': X_train, 'label': y_train})\n",
    "df_test = pd.DataFrame({'tweet': X_test, 'label': y_test})\n",
    "df_val = pd.read_csv('data/twitter/test.csv')\n",
    "\n",
    "df_train[df_train['label'] == 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   tweet  label\n12835                                                  1      1\n1025   2016highlights samwu fights various municipali...      1\n15976  2017 entering trumpdarkzone trump myoneresolut...      1\n11444  299 2016release ebook book summer melted every...      1\n15265  2nites church service look user back ur bible ...      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12835</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1025</th>\n      <td>2016highlights samwu fights various municipali...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15976</th>\n      <td>2017 entering trumpdarkzone trump myoneresolut...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11444</th>\n      <td>299 2016release ebook book summer melted every...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15265</th>\n      <td>2nites church service look user back ur bible ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.sw = set(get_stop_words(\"en\"))\n",
    "        self.punctuations = set(punctuation)\n",
    "        self.tokenization = MorphAnalyzer()\n",
    "\n",
    "    @staticmethod\n",
    "    def rm_at_sign(text):\n",
    "        return re.sub(r'[@]\\w+|\\w+@[\\w.]+', '', text, flags=re.DOTALL)\n",
    "\n",
    "    @staticmethod\n",
    "    def rm_hashtags(text):\n",
    "        return re.sub(r'#\\w+', '', text, flags=re.DOTALL)\n",
    "\n",
    "    @staticmethod\n",
    "    def rm_num(text):\n",
    "        return re.sub(r'^\\s*\\d+\\s*|\\s*$', '', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def rm_brackets(text):\n",
    "        return re.sub(r'\\[|\\]', '', text, flags=re.DOTALL)\n",
    "\n",
    "    @staticmethod\n",
    "    def rm_links(text):\n",
    "        return re.sub(r'https?://\\S+', '', text, flags=re.DOTALL)\n",
    "\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = str(text)\n",
    "        text = text.lower()\n",
    "        text = self.rm_num(text)\n",
    "        # text = self.rm_at_sign(text)\n",
    "        # text = self.rm_hashtags(text)\n",
    "        # text = self.rm_links(text)\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "        text = ''.join(c for c in text if c not in self.punctuations)\n",
    "        text = [self.tokenization.parse(word)[0].normal_form for word in text.split() if word not in self.sw]\n",
    "\n",
    "        return \" \".join(text)\n",
    "\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "df_train['tweet'] = df_train['tweet'].apply(preprocessor.preprocess)\n",
    "df_train = df_train[~df_train['tweet'].isin([''])]\n",
    "\n",
    "df_test['tweet'] = df_test['tweet'].apply(preprocessor.preprocess)\n",
    "\n",
    "df_train[df_train['label'] == 1].sort_values('tweet').head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 20811\n",
      "1: 1558\n"
     ]
    }
   ],
   "source": [
    "size_0 = df_train[df_train['label'] == 0].shape[0]\n",
    "size_1 = df_train[df_train['label'] == 1].shape[0]\n",
    "print('0:', size_0)\n",
    "print('1:', size_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "data": {
      "text/plain": "1558"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlpaug.augmenter.word import SynonymAug\n",
    "\n",
    "aug = SynonymAug(aug_src='wordnet', aug_p=1.0)\n",
    "\n",
    "df_train_class1 = df_train[df_train['label'] == 1]\n",
    "\n",
    "new_aug = []\n",
    "\n",
    "for text in df_train_class1['tweet']:\n",
    "    if len(text):\n",
    "        augmented_text = aug.augment(text)\n",
    "        new_aug.append(augmented_text[0])\n",
    "\n",
    "# for text in new_aug:\n",
    "#     if len(text):\n",
    "#         augmented_text = aug.augment(text)\n",
    "#         new_aug.append(augmented_text[0])\n",
    "#\n",
    "#         if len(new_aug) >= size_0 - size_1:\n",
    "#             break\n",
    "\n",
    "len(new_aug)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### concatenate df_train + new_tweets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "new_tweets = pd.DataFrame({'tweet': new_aug, 'label': [1]*len(new_aug)})\n",
    "new_tweets.index = range(len(df_train), len(df_train) + len(new_tweets))\n",
    "\n",
    "df_train = pd.concat([df_train, new_tweets]).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3116\n",
      "20811\n"
     ]
    }
   ],
   "source": [
    "print(df_train[df_train['label'] == 1].shape[0])\n",
    "print(df_train[df_train['label'] == 0].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### LSTM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 36189\n",
      "num_words after: 14214\n"
     ]
    }
   ],
   "source": [
    "text_corpus_train = df_train['tweet'].values\n",
    "text_corpus_test = df_test['tweet'].values\n",
    "\n",
    "counts = Counter()\n",
    "for sequence in text_corpus_train:\n",
    "    counts.update(sequence.split())\n",
    "\n",
    "print(\"num_words before:\",len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))\n",
    "\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "class LSTMFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "\n",
    "        return self.sigmoid(lstm_out)\n",
    "\n",
    "lstm_init = LSTMFixedLen(len(vocab2index), 30, 20)\n",
    "optimizer = torch.optim.Adam(lstm_init.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "class TwitterDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, txts, labels, w2index, used_length):\n",
    "        self._txts = txts\n",
    "        self._labels = labels\n",
    "        self._length = used_length\n",
    "        self._w2index = w2index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._txts)\n",
    "\n",
    "    @lru_cache(50000)\n",
    "    def encode_sentence(self, txt):\n",
    "        encoded = np.zeros(self._length, dtype=int)\n",
    "        enc1 = np.array([self._w2index.get(word, self._w2index[\"UNK\"]) for word in txt.split()])\n",
    "        length = min(self._length, len(enc1))\n",
    "        encoded[:length] = enc1[:length]\n",
    "        return encoded, length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded, length = self.encode_sentence(self._txts[index])\n",
    "        return torch.from_numpy(encoded.astype(np.int32)), self._labels[index], length"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "y_train = df_train['label'].values\n",
    "y_test = df_test['label'].values\n",
    "\n",
    "train_dataset = TwitterDataset(text_corpus_train, y_train, vocab2index, 27)\n",
    "test_dataset = TwitterDataset(text_corpus_test, y_test, vocab2index, 27)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdbdf956265d4a659a54c2978531a9c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 valid_loss 0.4172949492931366\n",
      "Epoch 1 valid_loss 0.4072824716567993\n",
      "Epoch 2 valid_loss 0.39986565709114075\n",
      "Epoch 3 valid_loss 0.3798901438713074\n",
      "Epoch 4 valid_loss 0.37539777159690857\n",
      "Epoch 5 valid_loss 0.36526721715927124\n",
      "Epoch 6 valid_loss 0.36206525564193726\n",
      "Epoch 7 valid_loss 0.3614402711391449\n",
      "Epoch 8 valid_loss 0.36335626244544983\n",
      "Epoch 9 valid_loss 0.3611094057559967\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for epoch in tqdm(range(10)):\n",
    "    lstm_init.train()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels, lengths = data[0], data[1], data[2]\n",
    "        inputs = inputs.int()\n",
    "        labels = labels.float().view(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = lstm_init(inputs, lengths)\n",
    "\n",
    "        last_outputs = outputs[range(outputs.size(0)), lengths-1, -1]\n",
    "        last_outputs = last_outputs.squeeze(-1)\n",
    "        labels = labels.float().squeeze(-1)\n",
    "\n",
    "        loss = criterion(last_outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    lstm_init.eval()\n",
    "    losss = 0\n",
    "    for X, y, lengths in test_loader:\n",
    "        X = X.long()\n",
    "        y = y.long().view(-1, 1)\n",
    "        output = lstm_init(X, lengths)\n",
    "\n",
    "        last_output = output[range(output.size(0)), lengths-1, -1]\n",
    "        last_output = last_output.squeeze(-1)\n",
    "        y = y.float().squeeze(-1)\n",
    "\n",
    "\n",
    "        losss = criterion(last_output, y)\n",
    "        losss = losss.item()\n",
    "        #loss_accumed += loss\n",
    "    print(\"Epoch {} valid_loss {}\".format(epoch, losss))\n",
    "\n",
    "print('Training is finished!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}