{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "((181467, 3), (22683, 3))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/lesson_9/train.csv')\n",
    "df_val = pd.read_csv('data/lesson_9/val.csv')\n",
    "\n",
    "df_train.shape, df_val.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                               text  class\n0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "1    92063\n0    89404\nName: class, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading model.safetensors:   0%|          | 0.00/711M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46186b548f8346c78d87c63adde42989"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/499 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d50704df1f534066bd670faa8f0bfa8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.40M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6456bd4058934f36b16dceb1db3eceb7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "937d1c2b55074ab1bd40428a60d880ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "[{'label': 'POSITIVE', 'score': 0.9541073441505432}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment = pipeline('text-classification', model='blanchefort/rubert-base-cased-sentiment')\n",
    "sentiment('Этот ресторан отличный')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мартовские путёвки дорожают на глазах. только пару дней назад были за 66, уже 86 о_О\n",
      "label is 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'label': 'NEGATIVE', 'score': 0.9948994517326355}]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 11\n",
    "print(df_train.iloc[idx]['text'])\n",
    "print('label is', df_train.iloc[idx]['class'])\n",
    "sentiment(df_train.iloc[idx]['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['text'].apply(lambda x: x.lower())\n",
    "df_val['text'] = df_val['text'].apply(lambda x: x.lower())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2351ea8fe6dd4e83a769741baf9d0efa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a237e28469614c1a8db76368ad4bd9f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18a34b22160142c6934d278a3bd6500e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 14337, 33930, 77572, 10520, 84964, 15065, 33917,   102,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "example_text = 'Пример текста для токенизации'\n",
    "bert_input = tokenizer(example_text, padding='max_length', max_length=10, truncation=True, return_tensors='pt')\n",
    "\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['attention_mask'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "('При', 'текста')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.ids_to_tokens[14337], tokenizer.ids_to_tokens[77572]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Пример текста для токенизации [SEP] [PAD]\n"
     ]
    }
   ],
   "source": [
    "example_text = tokenizer.decode(bert_input.input_ids[0])\n",
    "print(example_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class TwitterDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, txts, labels):\n",
    "        self._labels = labels\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self._txts = [self.tokenizer(text, padding='max_length', max_length=10, truncation=True, return_tensors='pt') for text in txts]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._txts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self._txts[index], self._labels[index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "y_train = df_train['class'].values\n",
    "y_val = df_val['class'].values\n",
    "\n",
    "train_dataset = TwitterDataset(df_train['text'], y_train)\n",
    "valid_dataset = TwitterDataset(df_val['text'], y_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "torch.Size([64, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "for txt, lbl in train_loader:\n",
    "    print(txt.keys())\n",
    "    print(txt['input_ids'].shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        _, pooled_output = self.bert(input_ids=x, attention_mask=mask, return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.sigm(linear_output)\n",
    "        return final_layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "model = BertClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(model.linear.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertClassifier(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (sigm): Sigmoid()\n",
      ")\n",
      "Parameters full train: 177854978\n",
      "Parameters transfer learning: 1538\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print('Parameters full train:', sum([param.nelement() for param in model.parameters()]))\n",
    "print('Parameters transfer learning:', sum([param.nelement() for param in model.linear.parameters()]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2275/2836 [12:45<02:32,  3.68it/s]"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(2):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "\n",
    "    model.train()\n",
    "    for train_input, train_label in tqdm(train_loader):\n",
    "        mask = train_input['attention_mask'].to(device)\n",
    "        input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        train_label = train_label.to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "\n",
    "        batch_loss = criterion(output, train_label)\n",
    "        total_loss_train += batch_loss.item()\n",
    "\n",
    "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "        total_acc_train += acc\n",
    "\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    total_loss_val, total_acc_val = 0.0, 0.0\n",
    "    for val_input, val_label in valid_loader:\n",
    "        val_label = val_label.to(device)\n",
    "        mask = val_input['attention_mask'].to(device)\n",
    "        input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "\n",
    "        batch_loss = criterion(output, val_label)\n",
    "        total_loss_val += batch_loss.item()\n",
    "\n",
    "        acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "        total_acc_val += acc\n",
    "\n",
    "    print(\n",
    "        f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
    "        | Train Accuracy: {total_acc_train / len(train_dataset): .3f} \\\n",
    "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
    "        | Val Accuracy: {total_acc_val / len(valid_dataset): .3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}