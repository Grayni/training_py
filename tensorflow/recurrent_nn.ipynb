{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout, ConvLSTM1D\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "batch_size = 200\n",
    "maxlen = 100\n",
    "epochs = 15\n",
    "\n",
    "log_dir = \"logs\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "len train: 25000\n",
      "len test: 25000\n",
      "Pad sequences...\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Model...\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training...\n",
      "Epoch 1/15\n",
      "125/125 [==============================] - 48s 368ms/step - loss: 0.5402 - accuracy: 0.7044 - val_loss: 0.3551 - val_accuracy: 0.8402\n",
      "Epoch 2/15\n",
      "125/125 [==============================] - 45s 363ms/step - loss: 0.3213 - accuracy: 0.8726 - val_loss: 0.3504 - val_accuracy: 0.8482\n",
      "Epoch 3/15\n",
      "125/125 [==============================] - 48s 387ms/step - loss: 0.2499 - accuracy: 0.9067 - val_loss: 0.3593 - val_accuracy: 0.8484\n",
      "Epoch 4/15\n",
      "125/125 [==============================] - 47s 376ms/step - loss: 0.2012 - accuracy: 0.9278 - val_loss: 0.4208 - val_accuracy: 0.8440\n",
      "Epoch 5/15\n",
      "125/125 [==============================] - 46s 366ms/step - loss: 0.1608 - accuracy: 0.9416 - val_loss: 0.4709 - val_accuracy: 0.8278\n",
      "Epoch 6/15\n",
      "125/125 [==============================] - 47s 377ms/step - loss: 0.1356 - accuracy: 0.9517 - val_loss: 0.5657 - val_accuracy: 0.8301\n",
      "Epoch 7/15\n",
      "125/125 [==============================] - 46s 372ms/step - loss: 0.1044 - accuracy: 0.9620 - val_loss: 0.5362 - val_accuracy: 0.8283\n",
      "Epoch 8/15\n",
      "125/125 [==============================] - 46s 368ms/step - loss: 0.1009 - accuracy: 0.9646 - val_loss: 0.6438 - val_accuracy: 0.8273\n",
      "Epoch 9/15\n",
      "125/125 [==============================] - 48s 381ms/step - loss: 0.0846 - accuracy: 0.9704 - val_loss: 0.6658 - val_accuracy: 0.8261\n",
      "Epoch 10/15\n",
      "125/125 [==============================] - 47s 375ms/step - loss: 0.0656 - accuracy: 0.9774 - val_loss: 0.7878 - val_accuracy: 0.8264\n",
      "Epoch 11/15\n",
      "125/125 [==============================] - 47s 376ms/step - loss: 0.0608 - accuracy: 0.9797 - val_loss: 1.1304 - val_accuracy: 0.8213\n",
      "Epoch 12/15\n",
      "125/125 [==============================] - 48s 381ms/step - loss: 0.0604 - accuracy: 0.9791 - val_loss: 0.8292 - val_accuracy: 0.8257\n",
      "Epoch 13/15\n",
      "125/125 [==============================] - 48s 385ms/step - loss: 0.0608 - accuracy: 0.9788 - val_loss: 0.7585 - val_accuracy: 0.8210\n",
      "Epoch 14/15\n",
      "125/125 [==============================] - 48s 381ms/step - loss: 0.0444 - accuracy: 0.9854 - val_loss: 0.8636 - val_accuracy: 0.8231\n",
      "Epoch 15/15\n",
      "125/125 [==============================] - 47s 374ms/step - loss: 0.0425 - accuracy: 0.9855 - val_loss: 1.0711 - val_accuracy: 0.8237\n",
      "125/125 [==============================] - 9s 71ms/step - loss: 1.0711 - accuracy: 0.8237\n",
      "loss: 1.07108736038208, accuracy: 0.8236799836158752\n"
     ]
    }
   ],
   "source": [
    "def train_nn_1():\n",
    "    print('Loading...')\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    print(f'len train: {len(x_train)}')\n",
    "    print(f'len test: {len(x_test)}')\n",
    "\n",
    "    print('Pad sequences...')\n",
    "    x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "    x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "    print(f'x_train shape: {x_train.shape}')\n",
    "    print(f'x_test shape: {x_test.shape}')\n",
    "\n",
    "    print('Model...')\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.4))\n",
    "    model.add(Dense(34, activation='relu'))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(Dense(34, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(16, activation='elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    print('Training...')\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[tensorboard_callback]),\n",
    "\n",
    "    score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "    print(f'loss: {score}, accuracy: {acc}')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train_nn_1()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Conclusion:\n",
    "Изменение коэффициента в Dropout существенно влияет на точность модели. Так же количество эпох оказывает положительное влияние. LSTM позволяет модели стабильно применять прошлые изменения для улучшения настоящих последовательностей."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}